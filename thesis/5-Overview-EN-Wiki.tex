\chapter{Descriptive overview of Edit Filters on the English Wikipedia}
\label{chap:overview-en-wiki}

\section{Data}

\begin{comment}
vgl \cite{GeiHal2017}
iterative mixed method
combination of:
* quantitative methods: mining big data sets/computational social science
"begin with one or
more large (but often thin) datasets generated by a software platform, which has recorded digital
traces that users leave in interacting on that platform. Such researchers then seek to mine as much
signal and significance from these found datasets as they can at scale in order to answer a research
question"
* more traditional social science/qualitative methods, e.g. interviews, observations, experiments
\end{comment}

The \emph{abuse\_filter} and \emph{abuse\_filter\_action} tables from \emph{enwiki\_p} were downloaded on 6.01.2019 via quarry~\footnote{\url{https://quarry.wmflabs.org/}}.
The complete files can be found in the repository for the present paper~\cite{github}. % TODO add a more specific link

These tables, along with \emph{abuse\_filter\_log} and \emph{abuse\_filter\_history}, are created and used by the AbuseFilter MediaWiki extension~\cite{gerrit-abusefilter}.
Selected queries have been run against the \emph{abuse\_filter\_log} table as well.
Unfortunately, currently the \emph{abuse\_filter\_history} table is not exposed to the public due to security/privacy concerns~\cite{phabricator}.
We hope to be shortly able to access a view of this table in order to conduct historic inquirements.

The schemas of these tables can be viewed in Figures~\ref{fig:db-schemas-af},~\ref{fig:db-schemas-afl},~\ref{fig:db-schemas-afh} and~\ref{fig:db-schemas-afa}.

\begin{figure*}
\begin{verbatim}
abuse_filter
+--------------------+---------------------+------+-----+---------+----------------+
| Field              | Type                | Null | Key | Default | Extra          |
+--------------------+---------------------+------+-----+---------+----------------+
| af_id              | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment |
| af_pattern         | blob                | NO   |     | NULL    |                |
| af_user            | bigint(20) unsigned | NO   | MUL | NULL    |                |
| af_user_text       | varbinary(255)      | NO   |     | NULL    |                |
| af_timestamp       | binary(14)          | NO   |     | NULL    |                |
| af_enabled         | tinyint(1)          | NO   |     | 1       |                |
| af_comments        | blob                | YES  |     | NULL    |                |
| af_public_comments | tinyblob            | YES  |     | NULL    |                |
| af_hidden          | tinyint(1)          | NO   |     | 0       |                |
| af_hit_count       | bigint(20)          | NO   |     | 0       |                |
| af_throttled       | tinyint(1)          | NO   |     | 0       |                |
| af_deleted         | tinyint(1)          | NO   |     | 0       |                |
| af_actions         | varbinary(255)      | NO   |     |         |                |
| af_global          | tinyint(1)          | NO   |     | 0       |                |
| af_group           | varbinary(64)       | NO   | MUL | default |                |
+--------------------+---------------------+------+-----+---------+----------------+
\end{verbatim}
  \caption{abuse\_filter schema}~\label{fig:db-schemas-af}
\end{figure*}

\begin{figure*}
\begin{verbatim}
abuse_filter_log
+------------------+---------------------+------+-----+---------+----------------+
| Field            | Type                | Null | Key | Default | Extra          |
+------------------+---------------------+------+-----+---------+----------------+
| afl_id           | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment |
| afl_filter       | varbinary(64)       | NO   | MUL | NULL    |                |
| afl_user         | bigint(20) unsigned | NO   | MUL | NULL    |                |
| afl_user_text    | varbinary(255)      | NO   |     | NULL    |                |
| afl_ip           | varbinary(255)      | NO   | MUL | NULL    |                |
| afl_action       | varbinary(255)      | NO   |     | NULL    |                |
| afl_actions      | varbinary(255)      | NO   |     | NULL    |                |
| afl_var_dump     | blob                | NO   |     | NULL    |                |
| afl_timestamp    | binary(14)          | NO   | MUL | NULL    |                |
| afl_namespace    | tinyint(4)          | NO   | MUL | NULL    |                |
| afl_title        | varbinary(255)      | NO   |     | NULL    |                |
| afl_wiki         | varbinary(64)       | YES  | MUL | NULL    |                |
| afl_deleted      | tinyint(1)          | NO   |     | 0       |                |
| afl_patrolled_by | int(10) unsigned    | YES  |     | NULL    |                |
| afl_rev_id       | int(10) unsigned    | YES  | MUL | NULL    |                |
| afl_log_id       | int(10) unsigned    | YES  | MUL | NULL    |                |
+------------------+---------------------+------+-----+---------+----------------+
\end{verbatim}
  \caption{abuse\_filter\_log schema}~\label{fig:db-schemas-afl}
\end{figure*}

\begin{figure*}
\begin{verbatim}
abuse_filter_history
+---------------------+---------------------+------+-----+---------+----------------+
| Field               | Type                | Null | Key | Default | Extra          |
+---------------------+---------------------+------+-----+---------+----------------+
| afh_id              | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment |
| afh_filter          | bigint(20) unsigned | NO   | MUL | NULL    |                |
| afh_user            | bigint(20) unsigned | NO   | MUL | NULL    |                |
| afh_user_text       | varbinary(255)      | NO   | MUL | NULL    |                |
| afh_timestamp       | binary(14)          | NO   | MUL | NULL    |                |
| afh_pattern         | blob                | NO   |     | NULL    |                |
| afh_comments        | blob                | NO   |     | NULL    |                |
| afh_flags           | tinyblob            | NO   |     | NULL    |                |
| afh_public_comments | tinyblob            | YES  |     | NULL    |                |
| afh_actions         | blob                | YES  |     | NULL    |                |
| afh_deleted         | tinyint(1)          | NO   |     | 0       |                |
| afh_changed_fields  | varbinary(255)      | NO   |     |         |                |
| afh_group           | varbinary(64)       | YES  |     | NULL    |                |
+---------------------+---------------------+------+-----+---------+----------------+
\end{verbatim}
  \caption{abuse\_filter\_history schema}~\label{fig:db-schemas-afh}
\end{figure*}

\begin{figure*}
\begin{verbatim}
abuse_filter_action
+-----------------+---------------------+------+-----+---------+-------+
| Field           | Type                | Null | Key | Default | Extra |
+-----------------+---------------------+------+-----+---------+-------+
| afa_filter      | bigint(20) unsigned | NO   | PRI | NULL    |       |
| afa_consequence | varbinary(255)      | NO   | PRI | NULL    |       |
| afa_parameters  | tinyblob            | NO   |     | NULL    |       |
+-----------------+---------------------+------+-----+---------+-------+
\end{verbatim}
  \caption{abuse\_filter\_action schema}~\label{fig:db-schemas-afa}
\end{figure*}


\textbf{Interesting questions}
\begin{itemize}
    \item how many filters are there (were there over the years): 954 filters (stand: 06.01.2019); TODO: historically?; This includes deleted filters
    \item what do the most active filters do?: see~\ref{tab:most-active-actions}
    \item get a sense of what gets filtered (more qualitative): TODO: refine after sorting through manual categories; preliminary: vandalism; unintentional suboptimal behavior from new users who don't know better ("good faith edits") such as blanking an article/section; creating an article without categories; adding larger texts without references; large unwikified new article (180); or from users who are too lazy (to write proper edit summaries; editing behaviours and styles not suitable for an encyclopedia (poor grammar/not commiting to orthography norms; use of emoticons and !; ascii art?); "unexplained removal of sourced content" (636) may be an attempt to silence a view point the editor doesn't like; self-promotion(adding unreferenced material to BLP; "users creating autobiographies" 148;); harassment; sockpuppetry; potential copyright violations; that's more or less it actually. There's a third bigger cluster of maintenance stuff, such as tracking bugs or other problems, trying to sort through bot edits and such. For further details see the jupyter notebook.
        Interestingly, there was a guideline somewhere stating that no trivial behaviour should trip filters (e.g. starting every paragraph with a small letter;) I actually think, a bot fixing this would be more appropriate.
    \item has the willingness of the community to use filters increased over time?: looking at aggregated values of number of triggered filters per year, the answer is rather it's quite constant; TODO: plot it at a finer granularity
        when aggregating filter triggers per month, one notices that there's an overall slight upward tendency.
        Also, there is a dip in the middle of 2014 and a notable peak at the beginning of 2016, that should be investigated further.
    \item how often were (which) filters triggered: see \url{filter-lists/20190106115600_filters-sorted-by-hits.csv} and~\ref{tab:most-active-actions}; see also jupyter notebook for aggregated hitcounts over tagged categories
    \item percentage of triggered filters/all edits; break down triggered filters according to typology: TODO still need the complete abuse\_filter\_log table!; and probably further dumps in order to know total number of edits
    \item percentage filters of different types over the years: according to actions (I need a complete abuse\_filter\_log table for this!); according to self-assigned tags %TODO plot!
    \item what gets classified as vandalism? has this changed over time? TODO: (look at words and patterns triggered by the vandalism filters; read vandalism policy page); pay special attention to filters labeled as vandalism by the edit filter editors (i.e. in the public description) vs these I labeled as vandalism
\end{itemize}

\textbf{Questions on abuse\_filter table}
\begin{itemize}
    \item how many filters are there altogether
    \item how many are enabled/disabled?
    \item how many hidden filters? how many of them are enabled
    \item how many are marked as deleted? (how many of them are hidden?)
    \item how many global? (what does global mean?)
    \item how many throttled? (what does this mean?)
    \item how many currently trigger which action (disallow, warn, throttle, tag, ..)?
    \item explore timestamp (I think it means "last modified"): have a lot of filters been modified recently?
    \item what are the values in the "group" column? what do they mean?
    \item which are the most frequently triggered filters of all time?
    \item is it new filters that get triggered most frequently? or are there also very active old ones?
    \item how many different edit filter editors are there (af\_user)?
    \item categorise filters according to which name spaces they apply to; pay special attention to edits in user/talks name spaces (may be indication of filtering harassment)
\end{itemize}

\textbf{Questions on abuse\_filter\_log table}
\begin{itemize}
    \item how often were filters with different actions triggered? (afl\_actions)
    \item what types of users trigger the filters (IPs? registered?) : IPs: 16,489,266, logged in users: 6,984,897 (Stand 15.03.2019);
    \item on what articles filters get triggered most frequently (afl\_title)
    \item what types of user actions trigger filters most frequently? (afl\_action) (edit, delete, createaccount, move, upload, autocreateaccount, stashupload)
    \item in which namespaces get filters triggered most frequently?
\end{itemize}

\textbf{Questions on abuse\_filter\_action table}
\begin{itemize}
    \item how many filters trigger any particular action (at the moment)?
    \item how many different parameters are there (i.e. tags when tagging, or templates to show upon a warning)?
\end{itemize}

\textbf{Number of unique filters that were triggered each year since 2009:}
owing to quarries we have all the filters that were triggered from the filter log per year, from 2009 (when filters were first introduced/the MediaWiki extension was enabled) till end of 2018 with their corresponding number of times being triggered:
\begin{table}
  \centering
  \begin{tabular}{l r }
    % \toprule
    Year & Num of distinct filters \\
    \hline
    2009 & 220 \\
    2010 & 163 \\
    2011 & 161 \\
    2012 & 170 \\
    2013 & 178 \\
    2014 & 154 \\
    2015 & 200 \\
    2016 & 204 \\
    2017 & 231 \\
    2018 & 254 \\
    % \bottomrule
  \end{tabular}
  \caption{Count of distinct filters that got triggered each year}~\label{tab:active-filters-count}
\end{table}

data is still not enough for us to talk about a tendency towards introducing more filters (after the initial dip)

%TODO: number of filters cannot grow endlessly, every edit is checked against all of them and this consumes computing power! (and apparently haven't been chucked with Moore's law). is this the reason why number of filters has been more or less constanst over the years?
\begin{comment}
\url{https://en.wikipedia.org/wiki/Wikipedia:Edit_filter/Requested}
"Each filter takes time to run, making editing (and to some extent other things) slightly slower. The time is only a few milliseconds per filter, but with enough filters that adds up. When the system is near its limit, adding a new filter may require removing another filter in order to keep the system within its limits."
\end{comment}

\textbf{Most frequently triggered filters for each year:}
10 most active filters per year:
\begin{table}
  \centering
  \begin{tabular}{r r }
    % \toprule
    Filter ID & Hitcount & Publicly available description \\
    \hline
    135 & repeating characters & 175455 \\
    30 & "large deletion from article by new editors" & 160302 \\
    61 & "new user removing references" ("new user" is handled by "!("confirmed" in user\_groups)") & 147377 \\
    18 & Test type edits from clicking on edit bar & 133640 \\
    3 & "new user blanking articles" & 95916 \\
    172 & "section blanking" & 89710 \\
    50 & "shouting" (contribution consists of all caps, numbers and punctuation) & 88827 \\
    98 & "creating very short new article" & 80434 \\
    65 & "excessive whitespace" (note: "associated with ascii art and some types of vandalism") & 74098 \\
    132 & "removal of all categories" & 68607 \\
    % \bottomrule
  \end{tabular}
  \caption{10 most active filters in 2009}~\label{tab:most-active-2009}
\end{table}

\begin{table}
  \centering
  \begin{tabular}{r r }
    % \toprule
    Filter ID & Hitcount & Publicly available description \\
    \hline
    61 & "new user removing references" ("new user" is handled by "!("confirmed" in user\_groups)") & 245179 \\
    135 & repeating characters & 242018 \\
    172 & "section blanking" & 148053 \\
    30 & "large deletion from article by new editors" & 119226 \\
    225 & Vandalism in all caps & 109912 \\
    3 & "new user blanking articles" & 105376 \\
    50 & "shouting" (contribution consists of all caps, numbers and punctuation) & 101542 \\
    132 & "removal of all categories" & 78633 \\
    189 & BLP vandalism or libel & 74528 \\
    98 & "creating very short new article" & 54805 \\
    % \bottomrule
  \end{tabular}
  \caption{10 most active filters in 2010}~\label{tab:most-active-2010}
\end{table}

\begin{table}
  \centering
  \begin{tabular}{r r }
    % \toprule
    Filter ID & Hitcount & Publicly available description \\
    \hline
    61 & "new user removing references" ("new user" is handled by "!("confirmed" in user\_groups)") & 218493 \\
    135 & repeating characters & 185304 \\
    172 & "section blanking" & 119532 \\
    402 & New article without references & 109347 \\
    30 & Large deletion from article by new editors & 89151 \\
    3 & "new user blanking articles" & 75761 \\
    384 & Addition of bad words or other vandalism & 71911 \\
    225 & Vandalism in all caps & 68318 \\
    50 & "shouting" (contribution consists of all caps, numbers and punctuation) & 67425 \\
    432 & Starting new line with lowercase letters & 66480 \\
    % \bottomrule
  \end{tabular}
  \caption{10 most active filters in 2011}~\label{tab:most-active-2011}
\end{table}

\begin{table}
  \centering
  \begin{tabular}{r r }
    % \toprule
    Filter ID & Hitcount & Publicly available description \\
    \hline
    135 & repeating characters & 173830 \\
    384 & Addition of bad words or other vandalism & 144202 \\
    432 & Starting new line with lowercase letters & 126156 \\
    172 & "section blanking" & 105082 \\
    30 & Large deletion from article by new editors & 93718 \\
    3 & "new user blanking articles" & 90724 \\
    380 & Multiple obscenities & 67814 \\
    351 & Text added after categories and interwiki & 59226 \\
    279 & Repeated attempts to vandalize & 58853 \\
    225 & Vandalism in all caps & 58352 \\
    % \bottomrule
  \end{tabular}
  \caption{10 most active filters in 2012}~\label{tab:most-active-2012}
\end{table}

\begin{table}
  \centering
  \begin{tabular}{r r }
    % \toprule
    Filter ID & Hitcount & Publicly available description \\
    \hline
    135 & repeating characters & 133309 \\
    384 & Addition of bad words or other vandalism & 129807 \\
    432 & Starting new line with lowercase letters & 94017 \\
    172 & "section blanking" & 92871 \\
    30 & Large deletion from article by new editors & 85722 \\
    279 & Repeated attempts to vandalize & 76738 \\
    3 & "new user blanking articles" & 70067 \\
    380 & Multiple obscenities & 58668 \\
    491 & Edits ending with emoticons or ! & 55454 \\
    225 & Vandalism in all caps & 48390 \\
    % \bottomrule
  \end{tabular}
  \caption{10 most active filters in 2013}~\label{tab:most-active-2013}
\end{table}

\begin{table}
  \centering
  \begin{tabular}{r r }
    % \toprule
    Filter ID & Hitcount & Publicly available description \\
    \hline
    384 & Addition of bad words or other vandalism & 111570 \\
    135 & repeating characters & 111173 \\
    279 & Repeated attempts to vandalize & 97204 \\
    172 & "section blanking" & 82042 \\
    432 & Starting new line with lowercase letters & 75839 \\
    30  & Large deletion from article by new editors & 62495 \\
    3 & "new user blanking articles" & 60656 \\
    636 & Unexplained removal of sourced content & 52639 \\
    231 & Long string of characters containing no spaces & 39693 \\
    380 & Multiple obscenities & 39624 \\
    % \bottomrule
  \end{tabular}
  \caption{10 most active filters in 2014}~\label{tab:most-active-2014}
\end{table}

\begin{table}
  \centering
  \begin{tabular}{r r }
    % \toprule
    Filter ID & Hitcount & Publicly available description \\
    \hline
    650 & Creation of a new article without any categories & 226460 \\
    61 & New user removing references & 196986 \\
    636 & Unexplained removal of sourced content & 191320 \\
    527 & T34234: log/throttle possible sleeper account creations & 189911 \\
    633 & Possible canned edit summary & 162319 \\
    384 & Addition of bad words or other vandalism & 141534 \\
    279 & Repeated attempts to vandalize & 110137 \\
    135 & repeating characters & 99057 \\
    686 & IP adding possibly unreferenced material to BLP & 95356 \\
    172 & "section blanking" & 82874 \\
    % \bottomrule
  \end{tabular}
  \caption{10 most active filters in 2015}~\label{tab:most-active-2015}
\end{table}

\begin{table}
  \centering
  \begin{tabular}{r r }
    % \toprule
    Filter ID & Hitcount & Publicly available description \\
    \hline
    527 & T34234: log/throttle possible sleeper account creations & 437099 \\
    61 & New user removing references & 274945 \\
    650 & Creation of a new article without any categories & 229083 \\
    633 & Possible canned edit summary & 218696 \\
    636 & Unexplained removal of sourced content & 179948 \\
    384 & Addition of bad words or other vandalism & 179871 \\
    279 & Repeated attempts to vandalize & 106699 \\
    135 & repeating characters & 95131 \\
    172 & "section blanking" & 79843 \\
    30 & Large deletion from article by new editors & 68968 \\
    % \bottomrule
  \end{tabular}
  \caption{10 most active filters in 2016}~\label{tab:most-active-2016}
\end{table}

\begin{table}
  \centering
  \begin{tabular}{r r }
    % \toprule
    Filter ID & Hitcount & Publicly available description \\
    \hline
    61 & New user removing references & 250394 \\
    633 & Possible canned edit summary & 218146 \\
    384 & Addition of bad words or other vandalism & 200748 \\
    527 & T34234: log/throttle possible sleeper account creations & 192441 \\
    636 & Unexplained removal of sourced content & 156409 \\
    650 & Creation of a new article without any categories & 151604 \\
    135 & repeating characters & 80056 \\
    172 & "section blanking" & 70837 \\
    712 & Possibly changing date of birth in infobox & 59537 \\
    833 & Newer user possibly adding unreferenced or improperly referenced material & 58133 \\
    % \bottomrule
  \end{tabular}
  \caption{10 most active filters in 2017}~\label{tab:most-active-2017}
\end{table}

\begin{table}
  \centering
  \begin{tabular}{r r }
    % \toprule
    Filter ID & Hitcount & Publicly available description \\
    \hline
    527 & T34234: log/throttle possible sleeper account creations & 358210 \\
    61 & New user removing references & 234867 \\
    633 & Possible canned edit summary & 201400 \\
    384 & Addition of bad words or other vandalism & 177543 \\
    833 & Newer user possibly adding unreferenced or improperly referenced material & 161030 \\
    636 & Unexplained removal of sourced content & 144674 \\
    650 & Creation of a new article without any categories & 79381 \\
    135 & repeating characters & 75348 \\
    686 & IP adding possibly unreferenced material to BLP & 70550 \\
    172 & "section blanking" & 64266 \\
    % \bottomrule
  \end{tabular}
  \caption{10 most active filters in 2018}~\label{tab:most-active-2018}
\end{table}

\textbf{what do the most active filters do?}

\begin{table*}
  \centering
    \begin{tabular}{r p{10cm} p{5cm} }
    % \toprule
    Filter ID & Publicly available description & Actions \\
    \hline
      135 & repeating characters & tag, warn \\
      30 & "large deletion from article by new editors" & tag, warn \\
      61 & "new user removing references" ("new user" is handled by "!("confirmed" in user\_groups)") & tag \\
      18 & "test type edits from clicking on edit bar" (people don't replace Example texts when click-editing) & deleted in Feb 2012 \\
      3 & "new user blanking articles" & tag, warn \\
      172 & "section blanking" & tag \\
      50 & "shouting" (contribution consists of all caps, numbers and punctuation) & tag, warn \\
      98 & "creating very short new article" & tag \\
      65 & "excessive whitespace" (note: "associated with ascii art and some types of vandalism") & deleted in Jan 2010 \\
      132 & "removal of all categories" & tag, warn \\
      225 & "vandalism in all caps" (difference to 50? seems to be swear words, but shouldn't they be catched by 50 anyway?) & disallow \\
      189 & "BLP vandalism or libel" & tag \\
      402 & "new article without references" & deleted in Apr 2013, before that disabled with comment "disabling, no real use" \\
      384 & "addition of bad words or other vandalism" (seems to be a blacklist) & disallow \\
      432 & "starting new line with lower case letters" & tag, warn //I recall there was a rule of thumb recommending not to user filters for style things? although that's not really style, but rather wrong grammar.. \\
      380 & hidden; public comment "multiple obscenities" & disallow \\
      351 & "text added after categories and interwiki" & tag, warn \\
      279 & "repeated attempts to vandalise" & tag, throttle (triggered when someone hits "edit" repeatedly in a short ammount of time) \\
      491 & "edits ending with emoticons or !" & tag, warn \\
      636 & "unexplained removal of sourced content" & warn (that, together with 634 and 635 refutes my theory that warn always goes together with tag) \\
      231 & "long string of characters containing no spaces" (that's surely english though^^) & tag, warn \\
      650 & "creation of a new article without any categories" & (log only) \\
      527 & hidden; public comments "T34234: log/throttle possible sleeper account creations" & throttle \\
      633 & "possible canned edit summary" (apparently pre-filled on mobile though) & tag \\
      686 & "IP adding possible unreferenced material to BLP" (BLP= biography of living people? I thought, it was forbidden to edit them without a registered account) & (log only) \\
      712 & "possibly changing date of birth in infobox" ("possibly"? and I thought infoboxes were pre-generated from wikidata?) & (log only) \\
      833 & "newer user possibly adding a unreferenced or improperly referenced material" & (log only) \\
  \end{tabular}
  \caption{What do most active filters do?}~\label{tab:most-active-actions}
\end{table*}

A lot of filters are disabled/deleted bc:
* they hit too many false positives
* they were implemented to target specific incidents and these vandalism attempts stopped
* they were tested and merged into other filters
* there were too few hits and the conditions were too expensive

Multiple filters have the comment "let's see whether this hits something", which brings us to the conclusion that edit filter editors have the right and do implement filters they consider necessary


%\subsection{Types of edit filters}
%We can sort filters into categories along various criteria.
%For now we don't have a different criteria...

\section{Public and Hidden Filters}

The first noticeable typology is along the line public/private filters.

It is calling attention that nearly 2/3 of all edit filters are not viewable by the general public.

The guidelines call for hiding filters ``only where necessary, such as in long-term abuse cases where the targeted user(s) could review a public filter and use that knowledge to circumvent it.''~\cite{Wikipedia:EditFilter}.
Further, they suggest caution in filter naming and giving just simple description of the overall disruptive behaviour rather than naming specificuser that is causing the disruptions.
(The later is not always complied with, there are indeed filters named after the accounts causing a disruption.)

Only edit filter editors (who have the \emph{abusefilter-modify} permission) and editors with the \emph{abusefilter-view-private} permission can view hidden filters.
The later is given to edit filter helpers - editors interested in helping with edit filters who still do not meet certain criteria in order to be granted the full \emph{abusefilter-modify} permission, editors working with edit filters on other wikis interested in learning from the filter system on English Wikipedia, and Sockpuppet investigation clerks~\cite{Wikipedia:EditFilterHelper}.
As of March 17, 2019, there are 16 edit filter helpers on EN Wikipedia~\footnote{\url{https://en.wikipedia.org/wiki/Special:ListUsers/abusefilter-helper}}.
Also, all administrators are able to view hidden filters.

There is also a designated mailing list for discussing these: wikipedia-en-editfilters@lists.wikimedia.org.
It is specifically indicated that this is the communication channel to be used when dealing with harassment (by means of edit filters)~\cite{Wikipedia:EditFilter}.
It is signaled, that the mailing list is meant for sensitive cases only and all general discussions should be held on-wiki~\cite{Wikipedia:EditFilter}.

\begin{comment}
\url{https://en.wikipedia.org/wiki/Wikipedia:Edit_filter}
"Non-admins in good standing who wish to review a proposed but hidden filter may message the mailing list for details."
// what is "good standing"?
// what are the arguments for hiding a filter? --> particularly obnoctious vandals can see how their edits are being filtered and circumvent them; security through obscurity
// are users still informed if their edit triggers a hidden filter? - most certainly; the warnings logic has nothing to do with whether the filter is hidden or not

"For all filters, including those hidden from public view, a brief description of what the rule targets is displayed in the log, the list of active filters, and in any error messages generated by the filter. " //yeah, well, that's the public comment, aka name of the filter

"Be careful not to test sensitive parts of private filters in a public test filter (such as Filter 1): use a private test filter (for example Filter 2) if testing is required."

\end{comment}

\section{Types of edit filters: Manual Classification}

Apart from filter typologies that can be derived directly from the DB schema (available fields/existing features), we propose a manual classification of the types of edits edit filters found on the EN Wikipedia target (there are edit filters with different purposes).

Based on the GT methodology, we scrutinised all filters, with their patterns, comments and actions.
We found 3 big clusters of filters that we labeled ``vandalism'', ``good faith'' and ``maintenance''.
It was not always a straightforward desicion to determine what type of edits a certain filter is targeting.
This was of course, particularly challenging for private filters where only the public comment (name) of the filter was there to guide us.
On the other hand, guidelines state up-front that filters should be hidden only in cases of particularly persistent vandalism, in so far it is probably safe to establish that all hidden filters target some type of vandalism.
However, the classification was difficult for public filters as well, since oftentimes what makes the difference between a good-faith and a vandalism edit is not the content of the edit but the intention of the editor.
While there are cases of juvenile vandalism (putting random swear words in articles) or characters repetiton vandalism which are pretty obvious, that is not the case for sections or articles blanking for example.
In such ambiguous cases, we can be guided by the action the filter triggers (if it is ``disallow'' the filter is most probably targeting vandalism).
At the end, we labeled most ambiguous cases with both ``vandalism'' and ``good faith''.

In the subsections that follow we discuss the salient properties of each manually labeled category.


Following filter categories have been identified (sometimes, a filter was labeled with more than one tag):
%TODO make a diagramm with these
- Vandalism
  - hoaxing
  - silly vandalism (e.g. repeating characters, inserting swear words)
  - spam
  - sockpuppetry
  - long term abuse // there seems to be separate documentation for this, see notes;
  - harassment/personal attacks
    - doxxing
    - impersonation
  - trolling
  - copyright violation

  Labeled along the vandalism typology (check above)
  - link vandalism
  - abuse of tags
  - username vandalism
  - image vandalism
  - avoidant vandalism
  - talk page vandalism
  - page move vandalism
  - template vandalism
  - vandalbots

  Kind of similar:
  - seo
  - stockbroker vandalism
  - biased pov
  - self promotion
  - conflict of interest

Inbetween
- edit warring
- political controversy
- politically/religiously motivated hate

- Good faith
  - bad style ("unencyclopedic edits" e.g. citing a blog or mentioning a hypothetical future album release)
  - lazyness


- Maintenance
  - bugs
  - wiki policy (compliance therewith)
  - test filters

%TODO: develop and include memos
\subsection{Vandalism}
\begin{comment}
# Filters targetting vandalism

The vast majority of edit filters on EN Wikipedia could be said to target (different forms of) vandalism.
Examples herefor are filters for *juvenile* types of vandalism (inserting swear or obscene words or nonsence sequences of characters into articles), for *hoaxing* or for *link spam*.
In principle, one can open quite a few subcategories here (also check https://en.wikipedia.org/wiki/Wikipedia:Vandalism for a "in-house" classification of vandalism types on Wikipedia).
Some vandalism types seem to be more severe than others (*sock puppetry* or persistant *long term* vandals).
For these, often times, the implemented filters are **private**.
This means, only edit filter editors can view the exact filter pattern or the comments of these.
Although this clashes with the overall *transparency* of the project (is there a guideline subscribing to this value? couldn't find a specific mention), the reasoning here is that otherwise, persistent vandals will be able to check for the pattern of the filter targetting their edits and just find a new way around it~\cite{Wikipedia:EditFilter}.
There are also private filters targetting personal attack or abuse cases.
Here, filters are private in order to protect affected person(s)~\cite{Wikipedia:EditFilter}.

The current state is also an "improvement" compared to the initially proposed visibility level of edit filters.
In the initial version of the EditFilters Page (https://en.wikipedia.org/w/index.php?title=Wikipedia:Edit_filter&oldid=221158142) Andrew Garrett (User:Werdna), the author of the AbuseFilter MediaWiki extention, was suggesting that all filters should be private and only a group of previously approved users should be able to view them.

According to https://en.wikipedia.org/wiki/Wikipedia:Vandalism following (mostly disruptive) behaviours are **not vandalism**:
- boldly editing
- copyright violation
- disruptive editing or stubbornness --> edit warring
- edit summary omission
- editing tests by experimenting users: "Such edits, while prohibited, are treated differently from vandalism"
- harassment or personal attacks: "Personal attacks and harassment are not allowed. While some harassment is also vandalism, such as user page vandalism, or inserting a personal attack into an article, harassment in itself is not vandalism and should be handled differently."
- Incorrect wiki markup and style
- lack of understanding of the purpose of wikipedia: "editing it as if it were a different medium—such as a forum or blog—in a way that it appears as unproductive editing or borderline vandalism to experienced users."
- misinformation, accidental
- NPOV contraventions (Neutral point of view)
- nonsense, accidental: "sometimes honest editors may not have expressed themselves correctly (e.g. there may be an error in the syntax, particularly for Wikipedians who use English as a second language)."
- Policy and guideline pages, good-faith changes to: "If people misjudge consensus, it would not be considered vandalism;"
- Reversion or removal of unencyclopedic material, or of edits covered under the biographies of living persons policy: "Even factually correct material may not belong on Wikipedia, and removing such content when it is not in line with Wikipedia's standards is not vandalism."
- Deletion nominations: "Good-faith nominations of articles (or templates, non-article pages, etc) are not vandalism."

Several of these behaviours could actually be conceived as **good faith** edits.
And, for several of them (as noted in the **good faith memo**), it is not immediately distinguishable whether it's a **good faith** or a **vandalism** edit.
Ultimately, the "only" difference between the two arises from the motivation/context of the edit.

## Properties/Characteristics

- maliciously intended disruptive editing

motivations:
- seeking attention
- misusing the encyclopedia for own purposes (self-promotion, seo..)
- spreading wrong information
- defacing topics

## DEF Vandalism, according to Wikipedia
https://en.wikipedia.org/wiki/Wikipedia:Vandalism
"On Wikipedia, vandalism has a very specific meaning: editing (or other behavior) deliberately intended to obstruct or defeat the project's purpose, which is to create a free encyclopedia, in a variety of languages, presenting the sum of all human knowledge."
"The malicious removal of encyclopedic content, or the changing of such content beyond all recognition, without any regard to our core content policies of neutral point of view (which does not mean no point of view), verifiability and no original research, is a deliberate attempt to damage Wikipedia. There, of course, exist more juvenile forms of vandalism, such as adding irrelevant obscenities or crude humor to a page, illegitimately blanking pages, and inserting obvious nonsense into a page. Abusive creation or usage of user accounts and IP addresses may also constitute vandalism."

## Consequences of vandalism, vandalism management
https://en.wikipedia.org/wiki/Wikipedia:Vandalism
"Vandalism is prohibited. While editors are encouraged to warn and educate vandals, warnings are by no means a prerequisite for blocking a vandal (although administrators usually only block when multiple warnings have been issued). "

"Upon discovering vandalism, revert such edits, using the undo function or an anti-vandalism tool. Once the vandalism is undone, warn the vandalizing editor. Notify administrators at the vandalism noticeboard of editors who continue to vandalize after multiple warnings, and administrators should intervene to preserve content and prevent further disruption by blocking such editors. Users whose main or sole purpose is clearly vandalism may be blocked indefinitely without warning."

One of the strategies to spot vandalism is "Watching for edits tagged by the abuse filter. However, many tagged edits are legitimate, so they should not be blindly reverted. That is, do not revert without at least reading the edit." //mention of filters!

"Warn the vandal. Access the vandal's talk page and warn them. A simple note explaining the problem with their editing is sufficient. If desired, a series of warning templates exist to simplify the process of warning users, but these templates are not required. These templates include

    Level one: {{subst:uw-vandalism1}} This is a gentle caution regarding unconstructive edits; it encourages new editors to use a sandbox for test edits. This is the mildest warning.
    Level two: {{subst:uw-vandalism2}} This warning is also fairly mild, though it explicitly uses the word 'vandalism' and links to this Wikipedia policy.
    Level three: {{subst:uw-vandalism3}} This warning is sterner. It is the first to warn that further disruptive editing or vandalism may lead to a block.
    Level four: {{subst:uw-vandalism4}} This is the sharpest vandalism warning template, and indicates that any further disruptive editing may lead to a block without warning."
\end{comment}

\subsection{Good Faith}
\begin{comment}
# Good faith edits

Good faith is a term used by the Wikipedia community itself.
Most prominently in the phrase "Always assume good faith".

As I recently learned, apparently this guideline arose/took such a central position not from the very beginning of the existence of the collaborative encyclopedia.
It rather arose at a time when, after a significant growth in Wikipedia, it wasn't manageable to govern the project (and most importantly fight emergent vandalism which grew proportionally to the project's growth) manually anymore.
To counteract vandalism, a number of automated measures was applied.
These, however, had also unforseen negative consequences: they drove newcomers away~\cite{HalKitRied2011}(quote literature) (since their edits were often classified as "vandalism", because they were not familiar with guidelines / wiki syntax / etc.)
In an attempt to fix this issue, "Assume good faith" rose to a prominent position among Wikipedia's Guidelines.
(Specifically, the page was created on March 3rd, 2004 and was originally refering to good faith during edit wars.
An expansion of the page from December 29th 2004 starts refering to vandalism. https://en.wikipedia.org/w/index.php?title=Wikipedia:Assume_good_faith&oldid=8915036)

Today, in vandalism comabting (?), there are cautious guidelines and several escalation levels, before an editor is banned. (TODO: elaborate, maybe move to vandalism)
Users are urged to use the term "vandalism" carefully, since it tends to offend and drive people away.
("When editors are editing in good faith, mislabeling their edits as vandalism makes them less likely to respond to corrective advice or to engage collaboratively during a disagreement,"~\cite{Wikipedia:Vandalism})
Not all disruptive behaviour is vandalism, the guidelines suggest~\cite{Wikipedia:Vandalism}.

Examples of "good faith" edits that are non the less disruptive are not complying with Wiki syntax (mostly because of being unfamiliar with it), deleting a page instead of moving it, using improper redirects or publishing test changes.

Edit warring is not vandalism either~\cite{Wikipedia:Vandalism}.

Oftentimes, it isn't a trivial task to distinguish good faith from vandalism edits.
Based on content of the edit alone, it might be frankly impossible.
This is also signaled for example on the STiki page ("Uncertainty over malice: It can be tricky to differentiate between vandalism and good-faith edits that are nonetheless unconstructive.")~\cite{Wikipedia:STiki}
Following the guideline, a patrolling editor (or whoever reads) should asume good faith first and seek a converstation with the disrupting editor. (TODO: where is this suggested?)
Only if the disrupting editor proves to be uncooperating, ignores warnings and continues disruptive behaviour, their edits are to be labelled "vandalism".

## Properties/Characteristics

- mostly done by new editors, not familiar with syntax, norms, guidelines
- result in:
  - broken syntax
  - disregarding established processes (e.g. deleting something without running it through an Articles for Deletion process, etc.)
  - non encyclopedic edits (e.g. without sources/with improper sourcers; badly styled; or with a skewed point of view)

- there is also the guideline "be bold" (or similar), so one could expect to be able to for example add unwikified text, which is then corrected by somebody else

## Examples

Some of the filters in the "good faith" category target (public comment of the filter):
- test edits
- misplaced "#redirect" in articles
- moves to or from Module namespace
- Large creations by inexperienced users
- creation of a new article without any categories
- new user removing references
- Adding "example.jpg" to article space

## https://en.wikipedia.org/wiki/Wikipedia:Assume_good_faith
"Most people try to help the project, not hurt it. If this were untrue, a project like Wikipedia would be doomed from the beginning. "
\end{comment}

\subsection{Editors' motivation}
\begin{comment}
# Filter according to editor motivation

In some sense, the broader categories "vandalism" and "good faith" have something in common.
They are both **motivations** out of which the editors act when composing their corresponding edits.
As already signaled, on grounds of the edit contents alone, it is often not easy to distinguish whether we have to do with a "vandalism" or with a "good faith" edit.

So, very different (contrasting?) motivations may result in identical edits.
Does it make sense to label filters on these grounds then?
In ambiguous cases (there are also the relatively inambiguous ones such as the infamous "poop" vandalism), there is no easy way to tell the motivation of the editor (that is, unless a communication with the editor is attempted and it's pointed out that their edits are disruptive and how to go about it in order to make a constructive contribution), neither for edit filter managers nor for us as researchers.

In a way, "vandalism" and "good faith" cover all the possible experiences along the "motivation" axis:
one of them refers to the edits made out of good and the other to the ones made out of bad intentions.

("The road to hell is paved with good intentions.")

## Open questions

If discerning motivation is difficult, and, we want to achieve different results, depending on the motivation, that lead us to the question whether filtering is the proper mechanism to deal with disruptive edits.

# Memo new users

When comparing the *vandalism* and *good faith* memos, it comes to attention that both type of edits are usually performed by new(ly/recently registered) users (or IP addresses).

A user who just registered an account is most probably inexperienced with Wikipedia, not familiar with all policies and guidelines and perhaps nor with MediaWiki syntax.

It is also quite likely (to be verified against literature!) that majority of vandalism edits come from the same type of newly/recently registered accounts.
In general, it is highly unlikely that an established Wikipedia editor should at once jeopardise the encyclopedia's purpose and start vandalising.
\end{coment}

\subsection{Maintenance}

\begin{comment}
# Filters with maintenance purpose

Some of the encountered edit filters on the EN Wikipedia were targeting neither vandalism nor good faith edits.
These had rather their focus on (semi-)automating routine (clean up) tasks.

Some of the filters I labeled as "maintenance" were for instance recording cases of broken syntax caused by a faulty browser extention. (filter id!)
Others were targeting bugs such as.. 

577 -> "VisualEditor bugs: Strange icons"
345 -> "Extraneous formatting from browser extension"
313 -> "Skype Toolbar Formatting"
199 -> "Unflagged Bots"
505 -> "Tag mobile edits"
728 -> "Huggle"
209 -> "arwiki interwiki problem"

The maintenance parent category differs conceptually from the other 2 in so far that filters in it don't target particular **intents** of the editors whose edits are triggering the filter, but rather "side"-occurances that mostly went wrong.

## Bugs

There are some 10 or so filters I manually labeled as targeting "bugs".
Most of them do log only.
\end{comment}

\chapter{Background}
\label{chap:background}

\section{Vandalism on Wikipedia}

Edit filters were initially introduced as a vandalism prevention mechanism (one of several).
The aim of this section is to provide a better understanding of vandalism on Wikipedia. (What is vandalism, and what not; who engages in vandalism; who is striving to prevent it and with what means)

\url{https://en.wikipedia.org/wiki/Wikipedia:Vandalism}

"This is not a noticeboard for vandalism. Report vandalism from specific users at Wikipedia:Administrator intervention against vandalism, or Wikipedia:Requests for page protection for specific pages.
Not to be confused with Wikipedia:Disruptive editing."

"This page documents an English Wikipedia policy."

"This page in a nutshell: Intentionally making abusive edits to Wikipedia will result in a block."

DEF Vandalism:
"On Wikipedia, vandalism has a very specific meaning: editing (or other behavior) deliberately intended to obstruct or defeat the project's purpose, which is to create a free encyclopedia, in a variety of languages, presenting the sum of all human knowledge."
"The malicious removal of encyclopedic content, or the changing of such content beyond all recognition, without any regard to our core content policies of neutral point of view (which does not mean no point of view), verifiability and no original research, is a deliberate attempt to damage Wikipedia. There, of course, exist more juvenile forms of vandalism, such as adding irrelevant obscenities or crude humor to a page, illegitimately blanking pages, and inserting obvious nonsense into a page. Abusive creation or usage of user accounts and IP addresses may also constitute vandalism."

Consequences of vandalism, vandalism management
"Vandalism is prohibited. While editors are encouraged to warn and educate vandals, warnings are by no means a prerequisite for blocking a vandal (although administrators usually only block when multiple warnings have been issued). "

"Even if misguided, willfully against consensus, or disruptive, any good-faith effort to improve the encyclopedia is not vandalism."
"For example, edit warring over how exactly to present encyclopedic content is not vandalism." !!!
"Careful consideration may be required to differentiate between edits that are beneficial, edits that are detrimental but well-intentioned, and edits that are vandalism."
"If it is clear that the editor in question is intending to improve Wikipedia, those edits are not vandalism, even if they violate some other core policy of Wikipedia."
"When editors are editing in good faith, mislabeling their edits as vandalism makes them less likely to respond to corrective advice or to engage collaboratively during a disagreement,"

Handling
"Upon discovering vandalism, revert such edits, using the undo function or an anti-vandalism tool. Once the vandalism is undone, warn the vandalizing editor. Notify administrators at the vandalism noticeboard of editors who continue to vandalize after multiple warnings, and administrators should intervene to preserve content and prevent further disruption by blocking such editors. Users whose main or sole purpose is clearly vandalism may be blocked indefinitely without warning."

"examples of suspicious edits are those performed by IP addresses, red linked, or obviously improvised usernames"

One of the strategies to spot vandalism is "Watching for edits tagged by the abuse filter. However, many tagged edits are legitimate, so they should not be blindly reverted. That is, do not revert without at least reading the edit."

"Warn the vandal. Access the vandal's talk page and warn them. A simple note explaining the problem with their editing is sufficient. If desired, a series of warning templates exist to simplify the process of warning users, but these templates are not required."

Types of vandalism \url{https://en.wikipedia.org/wiki/Wikipedia:Vandalism#Types_of_vandalism}:
  (Abuse of tags; Account creation, malicious; Avoidant vandalism; Blanking, illegitimate; Copyrighted material, repeated uploading of; Edit summary vandalism; Format vandalism; Gaming the system; Hidden vandalism; Hoaxing vandalism; Image vandalism; Link vandalism; Page creation, illegitimate; Page lengthening; Page-move vandalism; Silly vandalism; Sneaky vandalism; Spam external linking; Stockbroking vandalism; talk page vandalism; Template vandalism; User and user talk page vandalism; Vandalbots;)

\url{https://en.wikipedia.org/wiki/Wikipedia:Disruptive_editing}

"Disruptive editing is not vandalism, though vandalism is disruptive."
"Disruptive editing is not always intentional. Editors may be accidentally disruptive because they don't understand how to correctly edit, or because they lack the social skills or competence necessary to work collaboratively "
Okay what are disruptive edits that are not vandalism? (apart from edit wars)

"sometimes attracts people who seek to exploit the site as a platform for pushing a single point of view, original research, advocacy, or self-promotion."
"not verifiable through reliable sources or insisting on giving undue weight to a minority view."

"Collectively, disruptive editors harm Wikipedia by degrading its reliability as a reference source and by exhausting the patience of productive editors who may quit the project in frustration when a disruptive editor continues with impunity."

examples of disruptive editing:
"Engages in "disruptive cite-tagging"; adds unjustified {{citation needed}} tags to an article when the content tagged is already sourced, uses such tags to suggest that properly sourced article content is questionable."
"Rejects or ignores community input: resists moderation and/or requests for comment, continuing to edit in pursuit of a certain point despite an opposing consensus from impartial editors."


\section{Quality-control mechanisms on Wikipedia}
%Context
Context of work: algorithmic quality-control mechanisms (bots, ORES, humans) -> filter?

%TODO Literature review!
Distinction filters/Bots: what tasks are handled by bots and what by filters (and why)? What difference does it make for admins? For users whose edits are being targeted?

socio-technical assemblages (see Geiger)

* Huggle, Twinkle, AWB, Bots exist nearly since the very beginning (2002?), why did the community introduce filters in 2009?

\subsection{Humans}
* what part of the quality control work do humans take over? (in contrast to the algorithmic mechanisms)

\url{https://en.wikipedia.org/wiki/Wikipedia:Recent_changes_patrol}

\subsection{Semi-automatic tools}

Huggle, Twinkle, STiki~\cite{WestKanLee2010}
\url{http://en.wikipedia.org/wiki/Wikipedia:STiki}

\url{https://en.wikipedia.org/wiki/Wikipedia:AutoWikiBrowser}

\url{https://en.wikipedia.org/wiki/User:Lupin/Anti-vandal_tool}
"Please be aware that the original author of AVT (Lupin) is no longer active on Wikipedia. The script is very old and might stop working at any time."
"By using the RC feed to check a wiki-page's differences against a list of common vandal terms, this tool will detect many of the commonly known acts of online vandalism. "

\cite{GeiHal2013}
"Huggle, the most widely-used, fully assisted, counter-
vandalism tool, were made within 1 minute of the
offending edit. It is interesting that reverts with STiki, a
newer and more sophisticated queue-based vandal fighting
tool, are more often made to somewhat older edits, with a
time-to-revert distribution that is closer to unassisted edits.
This suggests that Huggle and STiki are targeting different
kinds of edits"

They also suggest that Twinkle (on one side) and Huggle and STiki are not in the same class of semi-automated vandal fighting tools, with Twinkle beeing more "manual" than the other 2.

VandalProof~\cite{HalRied2012}

"Huggle, one of the most popular
antivanda lism editing tools on
Wikipedia, is written in C#.NET
and any user can download and
install it. Huggle lets editors roll back
changes with a single mouse click,
but because the tool is so powerful,
rollback permission is restricted to
administrators and a few thousand
other Wikipedia users."
"Huggle makes it easy to review
a series of recent revisions by
filtering them according to the
user’s preferences."~\cite{HalRied2012}

huggle also sends out warnings to the offending editor on revert~\cite{HalRied2012}

\subsection{Bots}

ClueBot NG
"ClueBot_NG uses state-of-the-art machine learning techniques to review all contributions to
articles and to revert vandalism,"~\cite{HalRied2012}
XLinkBot
"XLinkBot reverts contributions that create links to
blacklisted domains as a way of quickly and permanently dealing with spammers."~\cite{HalRied2012}
HBC AIV Helperbots and MartinBot
"AIV Helperbot turns a simple page into a dynamic
priority-based discussion queue to support administrators in their work of identifying and
blocking vandals"~\cite{HalRied2012}

AntiVandalBot~\cite{HalRied2012}

Bots not patrolling constantly but instead doing batch cleanup works~\cite{GeiHal2013}:
AWB, DumbBOT, EmausBot
(also from figures: VolkovBot, WikitanvirBot, Xqbot)

\subsection{ORES}

%\section{Harassment and bullying}

\section{Algorithmic Governance}

maybe move it to edit filters chapter

\begin{itemize}
    \item Hier sollte enthalten sein, welche Anwendungen in diesem Bereich bereits existieren und warum bei diesen ein Defizit besteht.
    \item Falls genutzt, sollten hier die entsprechenden Algorithmen erläutert werden.
    \item Es sollten die Ziele der Anwendungsentwicklung, d.h. die Anforderungen herausgearbeitet werden. Dabei sollte die bestehende Literatur geeignet integriert werden.
\end{itemize}

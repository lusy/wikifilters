\chapter{Background}
\label{chap:background}

The present work can be embedded in the context of (algorithmic) quality-control mechanisms on Wikipedia.
There is a whole ecosystem (syn?) of actors struggling to maintain the anyone-can-edit encyclopedia as good^^ and vandalism free as possible.
We want to be able to better understand the role of edit filters in the vandal fighting network of humans, bots, semi-automated tools, and the machine learning framework ORES.
After all, edit filters were introduced to Wikipedia quite late, compared to the remaining mechanisms: in 2009. %TODO: when was the other stuff introduced
To this end, in the current chapter we study scientific literature on vandalism in Wikipedia and the quality control mechanisms mentioned above.

\section{Vandalism on Wikipedia}
%TODO put here papers on vandalism

\section{Quality-control mechanisms on Wikipedia}

%TODO Literature review!
% How: within the subsections? as a separate section?

% Aim: I want to know why are there filters?
Distinction filters/Bots: what tasks are handled by bots and what by filters (and why)? What difference does it make for admins? For users whose edits are being targeted?

Why is it important we study these mechanisms?
- their relative usage increases/has increased since they were first introduced
    \cite{GeiRib2010}
    "at present, bots make 16.33\% of all edits."
    %TODO more recent data? the last month argument via recentchanges (vgl \cite{Geiger2017}) doesn't hold here
- the whole ecosystem is not transparent, especially for new users (see~\cite{ForGei2012}: "As it is, Kipsizoo is not even
sure whether a real person who deleted the articles or a bot." )
"Keeping traces obscure help the powerful to remain in power"~\cite{ForGei2012}
- "inofficial", run and maintained by the community
    \cite{GeiRib2010}
    "often-unofficial technologies have fundamentally
    transformed the nature of editing and administration in
    Wikipedia"
    "Of note is the fact that these tools are largely
    unofficial and maintained by members of the Wikipedia
    community."
- higher entry barriers: new users have to orientate themselves in the picture and learn to use the software (decentralised mode of governance, often "impenetrable for new editors", vgl~\cite{ForGei2012})
- gamification concerns (is fighting vandalism becoming a game where certain users aim to revert as many edits as possible in order to get a higher score; and as a consequence these same users often times enforce reverts more rigorously than recommended and also pick cases that are easy and fast to arbitrate and do not require much additional research)
    \cite{HalRied2012}
    "Some Wikipedians feel that such
    motivational measures have gone
    too far in making Wikipedia like a
    game rather than a serious project.
    One humorous entry even argues that
    Wikipedia has become a MMORPG—
    a massively multiplayer online role-
    playing game—with “monsters”
    (vandals) to slay, “experience”
    (edit or revert count) to earn, and
    “overlords” (administrators) to submit
    to (http://en.wikipedia.org/wiki/
    Wikipedia:MMORPG)."
- they change the system not only in matter of scale (using bots/tools is faster, hence more reverts are possible) but in matter of substance: how everything interacts with each other
- they enable efficient patrolling of articles by users with little to no knowledge about the particular contents (thanks to their representation of the edits/information: e.g. diffs)
    \cite{GeiRib2010}
    !! tools not only speed up the process but:
    "These tools greatly lower certain barriers to participation and render editing
    activity into work that can be performed by "average
    volunteers" who may have little to no knowledge of the
    content of the article at hand"


---

socio-technical assemblages (see Geiger)

%Numbers
\cite{GeiRib2010}
Check Figure 1: Edits to AIV by tool (in the meantime 10 years old. is there newer data on the topic??)
not really, see:
\cite{Geiger2017}
"In the English-lan-
guage Wikipedia, 22 of the 25 most active editors (by
number of edits) are bot accounts, and July 2017, they
made about 20\% of all edits to encyclopedia articles."
Geiger's evidence:
https://quarry.wmflabs.org/query/20703
Percent of bot edits in previous month (enwiki, all pages)
\begin{verbatim}
is_bot	edits	Percentage of all edits
0	    7619466	79.4974
1	    1965083	20.5026
\end{verbatim}

https://quarry.wmflabs.org/query/20704
Percent of bot edits in previous month (enwiki, articles only)
\begin{verbatim}
is_bot	edits	Percentage of all edits
0	    4273810	80.2025
1	    1054966	19.7975
\end{verbatim}

However, a month is a relatively small period and you can't make an argument about general trends based on it.
For instance, these same quarries ran on April 12, 2019 render following results:
https://quarry.wmflabs.org/query/35104
Percent of bot edits in previous month (enwiki, all pages)
\begin{verbatim}
is_bot	edits	Percentage of all edits
0	    6710916	89.7318
1	    767948	10.2682
\end{verbatim}

https://quarry.wmflabs.org/query/35105
Percent of bot edits in previous month (enwiki, articles only)
\begin{verbatim}
is_bot	edits	Percentage of all edits
0	    3426624	92.1408
1	    292274	7.8592
\end{verbatim}


\subsection{Humans}

Despite steady increase of the proportion of fully and semi-automated tools usage for fighting vandalism %TODO quote!
some of the quality control work is still done ``manually'' by humand editors.
These are, on one hand, editors who use the ``undo'' functionality from within the page's revision history.
On the other hand, there are also editors who engage with the classical/standard encyclopedia editing mechanism (click the ``edit'' button on an article, enter changes in the editor which opens, write an edit summary for the edit, click ``save'') rather than using further automated tools to aid them.
When editors use these mechanisms for vandalism fighting, oftentimes they haven't noticed the vandalising edits by chance but rather have been actively watching the pages in question. %TODO: quote watchlist, current paper by Halfaker
This also gives us a hint as to what type of quality control work humans take over: less obvious and less rapid, editors who patrol pages via watchlists have some relationship to/deeper expertise on the topic. %TODO quote needed.
%TODO vgl also funnel diagram incoming edits quality assurance by Halfaker


\subsection{Semi-automated tools}

Semi-automated tools used for vandalism fighting on Wikipedia were discussed by:
more popular/widely used:
STiki~\cite{WestKanLee2010}
\url{http://en.wikipedia.org/wiki/Wikipedia:STiki}
Huggle~\cite{GeiHal2013},~\cite{HalRied2012},\cite{GeiRib2010}
Twinkle
AWB
\url{https://en.wikipedia.org/wiki/Wikipedia:AutoWikiBrowser}
less popular/older, mentioned in older accounts or not discussed at all (there are also more tools, see for example \url{https://en.wikipedia.org/wiki/Category:Wikipedia_counter-vandalism_tools})
VandalProof~\cite{HalRied2012}
ARV
AIV
Lupin's Anti-vandal tool
\url{https://en.wikipedia.org/wiki/User:Lupin/Anti-vandal_tool}
"Please be aware that the original author of AVT (Lupin) is no longer active on Wikipedia. The script is very old and might stop working at any time."
"By using the RC feed to check a wiki-page's differences against a list of common vandal terms, this tool will detect many of the commonly known acts of online vandalism. "

In general, previous research seems to make a distinction of degree? between ``more'' automated tools such as Huggle and STiki and ``less'' automated ones such as Twikle~\cite{GeiHal2013}.

\cite{GeiHal2013}
"Huggle, the most widely-used, fully assisted, counter-
vandalism tool, were made within 1 minute of the
offending edit. It is interesting that reverts with STiki, a
newer and more sophisticated queue-based vandal fighting
tool, are more often made to somewhat older edits, with a
time-to-revert distribution that is closer to unassisted edits.
This suggests that Huggle and STiki are targeting different
kinds of edits"

"Huggle, one of the most popular
antivandalism editing tools on
Wikipedia, is written in C\#.NET
and any user can download and
install it. Huggle lets editors roll back
changes with a single mouse click,
but because the tool is so powerful,
rollback permission is restricted to
administrators and a few thousand
other Wikipedia users."
"Huggle makes it easy to review
a series of recent revisions by
filtering them according to the
user’s preferences."~\cite{HalRied2012}

huggle also sends out warnings to the offending editor on revert~\cite{HalRied2012}

\cite{GeiRib2010}
huggle description
"edits are contextually
presented in queues as they are made, and the user can
perform a variety of actions (including revert and warn) with
a single click. The software's built-in queuing mechanism,
which by default ranks edits according to a set of vandalism-
identification algorithms,"

"Users of Hugglei's automatic
ranking mechanisms do not have to decide for themselves
which edit they will view next"

huggle's ranking heuristics:
"in the default „filtered" queue, edits that contain a significant removal of content are placed
higher; those that completely replace a page with blank text
are even marked in the queue with a red "X"."
"anonymous users are viewed as more suspicious than
registered users, and edits by bots and Huggle users are not
even viewed at all."
"Users whose edits have been previously
reverted by a number of assisted users are viewed as even
more suspicious, and those who have been left warnings on
their user talk page (a process explained below) are
systematically sent to the top of the queue."

"This edit was placed into the queues of many
Huggle users, as the software prioritizes mass removal of
content by anonymous users who have vandalism warnings
left for them. In fact, a green “1” appeared next to the
article's name in the edit queue, indicating that a first-level
warning had been issued."

"In reporting the anonymous user to
AIV, the Huggle program collected three edits which had been
marked as vandalism in the previously-issued warnings."

"The Huggle software took note of the
fact that a report existed for this user at AIV, and asked the
administrator if he wished to issue a temporary block."

"Yet with four warnings and an active report at AIV, there was
nothing else Huggle could do in the name of this non-
administrator except append this incident of vandalism to his
original report, further attempting to enroll a willing
administrator into the ad-hoc vandal fighting network."


\cite{GeiRib2010}
Twinkle description:
"user interface extension that runs inside
of a standard web browser. Twinkle adds contextual links to
pages in Wikipedia allowing editors to perform complex tasks
with the click of a button – such as rolling back multiple edits
by a single user, reporting a problematic user to
administrators, nominating an article for deletion, and
temporarily blocking a user (for administrators only)."

Lupin's anti-vandal tool
"provides a real-
time in-browser feed of edits made matching certain
algorithms"

\subsection{Bots}

\cite{GeiRib2010}
BotDef
"Bots – short for „robots" – are fully-automated software
agents that perform algorithmically-defined tasks involved
with editing, maintenance, and administration in Wikipedia."

---

ClueBot NG
"ClueBot\_NG uses state-of-the-art machine learning techniques to review all contributions to
articles and to revert vandalism,"~\cite{HalRied2012}
XLinkBot
"XLinkBot reverts contributions that create links to
blacklisted domains as a way of quickly and permanently dealing with spammers."~\cite{HalRied2012}
HBC AIV Helperbots and MartinBot
"AIV Helperbot turns a simple page into a dynamic
priority-based discussion queue to support administrators in their work of identifying and
blocking vandals"~\cite{HalRied2012}

AntiVandalBot~\cite{HalRied2012}

Bots not patrolling constantly but instead doing batch cleanup works~\cite{GeiHal2013}:
AWB, DumbBOT, EmausBot
(also from figures: VolkovBot, WikitanvirBot, Xqbot)

\cite{GeiRib2010}
"“HBC AIV helperbot7” – automatically
removed the third vandal fighter's now-obsolete report."

\subsection{ORES}

\cite{HalTar2015}

"Today, we’re announcing the release of a new artificial intelligence service designed **to improve the way editors maintain the quality** of Wikipedia" (emphsis mine)
" This service empowers Wikipedia editors by helping them discover damaging edits and can be used to immediately “score” the quality of any Wikipedia article."

"these specs actually work to highlight potentially damaging edits for editors. This allows editors to triage them from the torrent of new edits and review them with increased scrutiny. " (probably triage the edits, not the specs)

"By combining open data and open source machine learning algorithms, our goal is to make quality control in Wikipedia more transparent, auditable, and easy to experiment with."

//so, purpose of ORES is quality control

"Our hope is that ORES will enable critical advancements in how we do quality control—changes that will both make quality control work more efficient and make Wikipedia a more welcoming place for new editors."

"ORES brings automated edit and article quality classification to everyone via a set of open Application Programming Interfaces (APIs). The system works by training models against edit- and article-quality assessments made by Wikipedians and generating automated scores for every single edit and article."

"English Wikipedians have long had automated tools (like Huggle and STiki ) and bots (like ClueBot NG) based on damage-detection AI to reduce their quality control workload.  While these automated tools have been amazingly effective at maintaining the quality of Wikipedia, they have also (inadvertently) exacerbated the difficulties that newcomers experience when learning about how to contribute to Wikipedia. "
"These tools encourage the rejection of all new editors’ changes as though they were made in bad faith," //NB!!!
"Despite evidence on their negative impact on newcomers, Huggle, STiki and ClueBot NG haven’t changed substantially since they were first introduced and no new tools have been introduced. " //what about the edit filters? when were Huggle,STiki and ClueBotNG introduced?

"decoupling the damage prediction from the quality control process employed by Wikipedians, we hope to pave the way for experimentation with new tools and processes that are both efficient and welcoming to new editors. "

caution: biases in AI
" An algorithm that flags edits as subjectively “good” or “bad”, with little room for scrutiny or correction, changes the way those contributions and the people who made them are perceived."

"Examples of ORES usage. WikiProject X’s uses the article quality model (wp10) to help WikiProject maintainers prioritize work (left). Ra·un uses an edit quality model (damaging) to call attention to edits that might be vandalism (right)." //interesting for the memo

"Popular vandal fighting tools, like the aforementioned Huggle, have already adopted our revision scoring service."

further ORES applications:
"  But revision quality scores can be used to do more than just fight vandalism. For example, Snuggle uses edit quality scores to direct good-faith newcomers to appropriate mentoring spaces,[4] and dashboards designed by the Wiki Education Foundation use automatic scoring of edits to surface the most valuable contributions made by students enrolled in the education program"


\section{Algorithmic Governance}

maybe move it to edit filters chapter

\begin{itemize}
    \item Hier sollte enthalten sein, welche Anwendungen in diesem Bereich bereits existieren und warum bei diesen ein Defizit besteht.
    \item Falls genutzt, sollten hier die entsprechenden Algorithmen erläutert werden.
    \item Es sollten die Ziele der Anwendungsentwicklung, d.h. die Anforderungen herausgearbeitet werden. Dabei sollte die bestehende Literatur geeignet integriert werden.
\end{itemize}

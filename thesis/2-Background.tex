\chapter{Background}
\label{chap:background}

\section{Vandalism on Wikipedia}

According to Wikipedia's newspaper, the Signpost, edit filters were initially introduced as a vandalism prevention mechanism (one of several)~\cite{Signpost2009}.
The aim of this section is to provide a better understanding of vandalism on Wikipedia. (What is vandalism, and what not; who engages in vandalism; who is striving to prevent it and with what means)

%What is vandalism

According to EN Wikipedia's policy~\cite{Wikipedia:Vandalism}, vandalism means ``intentionally making abusive edits to Wikipedia'' or, more specifically ``editing (or other behavior) deliberately intended to obstruct or defeat the project's purpose, which is to create a free encyclopedia''.
Vandalism includes ``malicious removal of encyclopedic content, or the changing of such content beyond all recognition, without any regard to our core content policies of neutral point of view (which does not mean no point of view), verifiability and no original research''
as well as ``adding irrelevant obscenities or crude humor to a page, illegitimately blanking pages, and inserting obvious nonsense into a page''
and ``[a]busive creation or usage of user accounts and IP addresses''.

Wikipedians have elaborated a whole vandalism typology~\cite{Wikipedia:Vandalism}, illustrated by figure~\ref{fig:vandalism-typology}.
\begin{comment}
Types of vandalism \url{https://en.wikipedia.org/wiki/Wikipedia:Vandalism#Types_of_vandalism}:
  (Abuse of tags; Account creation, malicious; Avoidant vandalism; Blanking, illegitimate; Copyrighted material, repeated uploading of; Edit summary vandalism; Format vandalism; Gaming the system; Hidden vandalism; Hoaxing vandalism; Image vandalism; Link vandalism; Page creation, illegitimate; Page lengthening; Page-move vandalism; Silly vandalism; Sneaky vandalism; Spam external linking; Stockbroking vandalism; talk page vandalism; Template vandalism; User and user talk page vandalism; Vandalbots;)
\end{comment}

%What is not vandalism

There are different types of edits viewed as disruptive by the Wikipedia community.
Edit warring and pushing a single point of view and disregarding community feedback are examples here of. %TODO what are other examples?
Nevertheless, the guidelines caution that ``[d]isruptive editing is not vandalism, though vandalism is disruptive''~\cite{Wikipedia:DisruptiveEditing}.
And that different procedures should be adopted by editors in both cases.

The vandalism policy also cautions about using the ``vandalism'' label since it tends to drive contributors away and prevent constructive discussions~\cite{Wikipedia:Vandalism}.
%TODO vgl good faith memo

\begin{comment}
\url{https://en.wikipedia.org/wiki/Wikipedia:Vandalism}
"Careful consideration may be required to differentiate between edits that are beneficial, edits that are detrimental but well-intentioned, and edits that are vandalism."
%TODO vgl with memo-good-faith

\url{https://en.wikipedia.org/wiki/Wikipedia:Disruptive_editing}

"Disruptive editing is not always intentional. Editors may be accidentally disruptive because they don't understand how to correctly edit, or because they lack the social skills or competence necessary to work collaboratively "
Okay what are disruptive edits that are not vandalism? (apart from edit wars)

"Engages in "disruptive cite-tagging"; adds unjustified {{citation needed}} tags to an article when the content tagged is already sourced, uses such tags to suggest that properly sourced article content is questionable."
\end{comment}

%Who engages in vandalism (and why?)

The policy signals clearly that editors repeatedly engaging in vandalism are subject to banning.
Furthermore, it is explained that although warnings for vandalism are issued in general, these are not a prerequisite for banning~\cite{Wikipedia:Vandalism}.
%TODO: still not explained who and why

%Who is striving to prevent vandalism? How do they go about it?

Since Wikipedia is a ``do-it-yourself'' project, every editor who notices vandalism is called upon to help fixing it.
There is a formal process for reporting users who engage in vandalism %TODO look up Administrator intervention against vandalism
and requesting page protection for frequently vandalised pages. %TODO quote
And there are also users who specifically dedicate substantial amount of their Wikipedia contributions to fighting vandalism.

These dedicated vandal fighters mostly do so with the aid of some (semi or fully) automated tools which significally speeds up the process (see below).

\section{Quality-control mechanisms on Wikipedia}
%Context
Context of work: algorithmic quality-control mechanisms (bots, ORES, humans) -> filter?

%TODO Literature review!
% How: within the subsections? as a separate section?
Distinction filters/Bots: what tasks are handled by bots and what by filters (and why)? What difference does it make for admins? For users whose edits are being targeted?

\cite{GeiRib2010}
Partial explanation why literature paid little attention to (semi-)automated tools up to this date:
- old data according to which bots accounted for a very little amount of edits (2-4%)
  ("that this number has grown
dramatically: at present, bots make 16.33% of all edits.")
- "largely involved in single-use tasks like importing public domain material" (so not the case anymore, check e.g. MusikBot)
- "characterized in the literature as mere force-multipliers,
increasing the speed with which editors perform their work
while generally leaving untouched the nature of the tasks
themselves"

!! tools not only speed up the process but:
"These tools greatly lower certain barriers to participation and render editing
activity into work that can be performed by „average
volunteers‟ who may have little to no knowledge of the
content of the article at hand"

critical discussion
"Such acts of inclusion and exclusion may be necessary, but
they are inherently moral in quality, speaking to questions of
who is left out and what knowledge is erased."

"It is for
this reason that the argument that bots and assisted editing
tools are merely force multipliers is narrow and dangerous"

"In and outside of the Wikipedian community, tools
like Huggle are often compared with video games in both
serious critiques and humorous commentaries:"

"We should not fall into the trap of speaking of bots and
assisted editing tools as constraining the moral agency of
editors"

"these tools makes certain pathways of action easier for vandal
fighters and others harder"

"Ultimately, these tools take their users
through standardized scripts of action in which it always
possible to act otherwise, but such deviations demand
inventiveness and time."

---

socio-technical assemblages (see Geiger)

* Huggle, Twinkle, AWB, Bots exist nearly since the very beginning (2002?), why did the community introduce filters in 2009?

\subsection{Humans}

Some of the quality control work is done ``manually'' by humand editors.
That means, they engage in the standard encyclopedia editing mechanism (click the ``edit'' button on an article, enter changes in the editor which opens, write an edit summary for the edit, click ``save'') rather than using further automated tools to aid them.
According to research focusing on vandalism fighting, the amount/share/proportion of editors who engage in counter-vandalism measures that way shrinks in favour of semi or fully automated tools. %TODO quotes!
* what part of the quality control work do humans take over? (in contrast to the algorithmic mechanisms)

\url{https://en.wikipedia.org/wiki/Wikipedia:Recent_changes_patrol}

\cite{GeiRib2010}
Check Figure 1: Edits to AIV by tool (in the meantime 10 years old. is there newer data on the topic??)

\subsection{Semi-automated tools}

%TODO consider adding screenshots

Huggle, Twinkle, STiki~\cite{WestKanLee2010}
\url{http://en.wikipedia.org/wiki/Wikipedia:STiki}

also ARV, AIVer

\url{https://en.wikipedia.org/wiki/Wikipedia:AutoWikiBrowser}

\url{https://en.wikipedia.org/wiki/User:Lupin/Anti-vandal_tool}
"Please be aware that the original author of AVT (Lupin) is no longer active on Wikipedia. The script is very old and might stop working at any time."
"By using the RC feed to check a wiki-page's differences against a list of common vandal terms, this tool will detect many of the commonly known acts of online vandalism. "

\cite{GeiHal2013}
"Huggle, the most widely-used, fully assisted, counter-
vandalism tool, were made within 1 minute of the
offending edit. It is interesting that reverts with STiki, a
newer and more sophisticated queue-based vandal fighting
tool, are more often made to somewhat older edits, with a
time-to-revert distribution that is closer to unassisted edits.
This suggests that Huggle and STiki are targeting different
kinds of edits"

They also suggest that Twinkle (on one side) and Huggle and STiki are not in the same class of semi-automated vandal fighting tools, with Twinkle beeing more "manual" than the other 2.

VandalProof~\cite{HalRied2012}

"Huggle, one of the most popular
antivanda lism editing tools on
Wikipedia, is written in C#.NET
and any user can download and
install it. Huggle lets editors roll back
changes with a single mouse click,
but because the tool is so powerful,
rollback permission is restricted to
administrators and a few thousand
other Wikipedia users."
"Huggle makes it easy to review
a series of recent revisions by
filtering them according to the
user’s preferences."~\cite{HalRied2012}

huggle also sends out warnings to the offending editor on revert~\cite{HalRied2012}

\cite{GeiRib2010}
huggle description
"edits are contextually
presented in queues as they are made, and the user can
perform a variety of actions (including revert and warn) with
a single click. The software‟s built-in queuing mechanism,
which by default ranks edits according to a set of vandalism-
identification algorithms,"

"Users of Huggle‟s automatic
ranking mechanisms do not have to decide for themselves
which edit they will view next"

huggle's ranking heuristics:
"in the default „filtered‟ queue, edits that contain a significant removal of content are placed
higher; those that completely replace a page with blank text
are even marked in the queue with a red „X‟."
"anonymous users are viewed as more suspicious than
registered users, and edits by bots and Huggle users are not
even viewed at all."
"Users whose edits have been previously
reverted by a number of assisted users are viewed as even
more suspicious, and those who have been left warnings on
their user talk page (a process explained below) are
systematically sent to the top of the queue."

"This edit was placed into the queues of many
Huggle users, as the software prioritizes mass removal of
content by anonymous users who have vandalism warnings
left for them. In fact, a green “1” appeared next to the
article‟s name in the edit queue, indicating that a first-level
warning had been issued."

"In reporting the anonymous user to
AIV, the Huggle program collected three edits which had been
marked as vandalism in the previously-issued warnings."

"The Huggle software took note of the
fact that a report existed for this user at AIV, and asked the
administrator if he wished to issue a temporary block."

"Yet with four warnings and an active report at AIV, there was
nothing else Huggle could do in the name of this non-
administrator except append this incident of vandalism to his
original report, further attempting to enroll a willing
administrator into the ad-hoc vandal fighting network."

\cite{GeiRib2010}
"often-unofficial technologies have fundamentally
transformed the nature of editing and administration in
Wikipedia"
"Of note is the fact that these tools are largely
unofficial and maintained by members of the Wikipedia
community."
//refers also to bots

\cite{GeiRib2010}
Twinkle description:
"user interface extension that runs inside
of a standard web browser. Twinkle adds contextual links to
pages in Wikipedia allowing editors to perform complex tasks
with the click of a button – such as rolling back multiple edits
by a single user, reporting a problematic user to
administrators, nominating an article for deletion, and
temporarily blocking a user (for administrators only)."

Lupin's anti-vandal tool
"provides a real-
time in-browser feed of edits made matching certain
algorithms"

\subsection{Bots}

\cite{GeiRib2010}
BotDef
"Bots – short for „robots‟ – are fully-automated software
agents that perform algorithmically-defined tasks involved
with editing, maintenance, and administration in Wikipedia."

---

ClueBot NG
"ClueBot_NG uses state-of-the-art machine learning techniques to review all contributions to
articles and to revert vandalism,"~\cite{HalRied2012}
XLinkBot
"XLinkBot reverts contributions that create links to
blacklisted domains as a way of quickly and permanently dealing with spammers."~\cite{HalRied2012}
HBC AIV Helperbots and MartinBot
"AIV Helperbot turns a simple page into a dynamic
priority-based discussion queue to support administrators in their work of identifying and
blocking vandals"~\cite{HalRied2012}

AntiVandalBot~\cite{HalRied2012}

Bots not patrolling constantly but instead doing batch cleanup works~\cite{GeiHal2013}:
AWB, DumbBOT, EmausBot
(also from figures: VolkovBot, WikitanvirBot, Xqbot)

\cite{GeiRib2010}
"“HBC AIV helperbot7” – automatically
removed the third vandal fighter‟s now-obsolete report."

\subsection{ORES}

%\section{Harassment and bullying}

\section{Algorithmic Governance}

maybe move it to edit filters chapter

\begin{itemize}
    \item Hier sollte enthalten sein, welche Anwendungen in diesem Bereich bereits existieren und warum bei diesen ein Defizit besteht.
    \item Falls genutzt, sollten hier die entsprechenden Algorithmen erläutert werden.
    \item Es sollten die Ziele der Anwendungsentwicklung, d.h. die Anforderungen herausgearbeitet werden. Dabei sollte die bestehende Literatur geeignet integriert werden.
\end{itemize}

\cite{MuellerBirn2014}

Interesting info, not sure what to do with it

2010: 40% of newcommers' contributions rejected based on automatic tools <---
counter productive in engaging new contributors

=====================================================
\cite{GeiHal2017}

Claudia's paper:
"“In both cases of algorithmic governance
– software features and bots – making rules part of the infrastructure, to a certain extent, makes
them harder to change and easier to enforce” (p. 87)"

=====================================================
\cite{MueDoHer2013}
1st major difference EN/DE Wikipedia:
- automated vandal fighting not permitted in DE Wikipedia (ist es immer noch
  so?)
"algorithmic tools are only intended to support editors in identify-
ing possible malicious edits, but automated assessments are not
accepted"
"Fighting vandals is seen as a form of handling excep-
tions and should therefore be based upon human evaluation."

Hoe? DE Wikipedia has also edit filters which is an automatic assessment of what to disallow.
\cite{WulThaDix2017}

personal attacks

methodology: crowd-sourcing + machine learning
looked at comments on Wikipedia talk pages
100k human labeled comments
63k machine labeled (classifier)
generated data set:
https://figshare.com/Grticles/Wikipedia_Detox_Data/4054689

analysed time period: 2004-2015

"The primary contribution of this paper is a methodology for quan-
titative, large-scale, longitudinal analysis of a large corpus of on-
line comments."

Questions:
"What is the impact of allowing anonymous contributions, namely those from unregistered users?
How do attacks vary with the quantity of a user’s contributions?
Are attacks concentrated among a few users?
When do attacks result in a moderator action?
And is there a pattern to the timing of personal attacks?"

"the majority of personal attacks on Wikipedia are not
the result of a few malicious users, nor primarily the consequence
of allowing anonymous contributions from unregistered users"

"Report highlights that 73% of adult internet users have seen some-
one harassed online, and 40% have personally experienced it [5]."

"Platforms combat this with policies"
"Wikipedia has a policy of “Do not make personal attacks
anywhere in Wikipedia”[33] and notes that attacks may be removed
and the users who wrote them blocked. 1"

classifier: "character-level n-
grams result in an impressively flexible and performant classifier
for a variety of abusive language in English."

"The Wikimedia Foundation found that
54% of those who had experienced online harassment expressed
decreased participation in the project where they experienced the
harassment [23]"

"Through labeling
a random sample, we discovered that the overall prevalence of per-
sonal attacks on Wikipedia talk pages is around 1% (see Section
5.1)."

"Annotators whose accuracy on these test questions fell below a 70%
threshold would be removed from the task."
"This allows us to aggregate judgments
from 10 separate people when constructing a single label for each
comment. We chose 10 judgments based on experiments in Sec. 4.3"

note: the annotators could be biased and their judgement on what is a personal attack may differ from this of the Wikipedian community

"approximately 30% of attacks
come from registered users with over 100 contributions."
"that less than a fifth of personal attacks currently trigger any action
for violating Wikipedia’s policy."
"personal attacks clus-
ter in time - perhaps because one personal attacks triggers another.
If so, early intervention by a moderator could have a disproportion-
ately beneficial impact."

discussion:
"While there are many such questions to analyze,
some notable examples include:
1. What is the impact of personal attacks on a user’s future con-
tributions?
2. What interventions can reduce the level of personal attacks
on a conversation?
3. What are the triggers for personal attacks in Wikipedia com-
ments?"

======================================================
\cite{Geiger2011}

discusses the acceptance, coming into existence and live cycle of bots
begins by a story of elections for the Arbitration Committee (ArbCom), where a bot was nominated, which was taken with different degrees of seriousness (and frustration) by different editors
then discusses at length the discussions around the HagermanBot (signing discussion entries)
and the eventually created opt-out possibilities when it comes to be processed by a bot

touches on philosophical and moral discussions about what is a bot, what rights a bot has and what rights of human editors must be put first

touches on ANT when justifying the need to discuss bots as actors on the same level as humans

"Tawker,
speaking through his bot, was ironically claiming that computerized editors ought to have the
same sociopolitical rights and responsibilities as human editors,"
"I argue (with all seriousness) that these automated software
agents already have a similar level of influence on how Wikipedia as a free and open ency-
clopedia project is constituted."
"we must be careful not to fall into familiar narra-
tives of technological determinism when asking who – or what – actually controls Wikipedia."

cites some stats to underline the (growing) importance of bots
then discusses previous research which seem not to pay the due attention to bots (sometimes with the justification bots are not important enough which lies on old data and sometimes with no justification at all)

"While bots were
originally built to perform repetitive editorial tasks that humans were already doing, they are
growing increasingly sophisticated and have moved into administrative spaces. Bots now po-
lice not only the encyclopedic nature of content contributed to articles, but also the sociality
of users who participate in the community."

"Administrative Intervention against Vandalism, or AIV),
bots make about 50% of all edits, and users with semi-automated editing tools make another
30%"

"My goal in this chapter is to describe the complex social and technical environment in which
bots exist in Wikipedia, emphasizing not only how bots produce order and enforce rules, but
also how humans produce bots and negotiate rules around their operation."

"Operators of bots have also expressed
frustration when their bots become naturalized, that is, when users assume that the bot’s
actions are features of the project’s software instead of work performed by their diligent
computerized workers. In general, bots tend to be taken for granted, and when they are
discussed, they are not largely differentiated from human editors"

"We must pay close attention to both the material and semiotic conditions
in which bots emerge within the complex collective of editors, administrators, committees,
discussions, procedures, policies, and shared understandings that make up the social world
of Wikipedia."

"Bots, like infrastructures in general, 23 simultaneously produce and rely upon
a particular vision of how the world is and ought to be, a regime of delegation that often
sinks into the background – that is, until they do not perform as expected and generate
intense controversies."
//important! signal when discussing filters as well!
//quotes Star 1999 "The Ethnography of Infrastructure"

". This controversy illustrated that a particular kind of normative enforce-
ment and correction, while acceptable when casually performed on a fraction of violations
sometimes days or weeks after, became quite different when universally and immediately
implemented by a bot."

high level issues of rights and responsibilities emerged
"social understanding that ‘bots ought to be better behaved than people’,"

HagermanBot
- explains the origins of the signatures guideline

criticism of the HagermanBot:
- "For these editors, HagermanBot’s message was ‘embarrassing’, as one editor stated, making them ap-
pear as if they had blatantly violated the Signatures guideline"
- "Others did not want bots editing messages other users left for them on their own user talk pages as a matter of principle,"
- "and an equally vocal group did not want the bots adding signatures to their own comments."

Reasons for
"it seemed that Hagerman had a strong set of allies: a growing number of
enthusiastic supporters, the BAG, the Signatures guideline, ideals of openness and transpar-
ency, visions of an ideal discursive space, the {{unsigned}} template, and a belief that signing
unsigned comments was a routine act that had long been performed by humans."

objections
"Yet for some reason, a growing number of editors objected to this typical, uncontroversial practice
when HagermanBot performed it."
"they portrayed as an unfair imposition of what they believed
ought to be optional guidelines. The anti-HagermanBot group was diverse in their stated ra-
tionales and suggested solutions, but all objected to the bot’s operation on some level."

"In the ensuing discussion – which was comprised of BAG members, administrators, and
other Wikipedians – it became clear that this was not simply a debate about signatures and
timestamps."
"full-blown controversy about the morality of delegat-
ing social tasks to technologies,"

Supporters:
"claiming that HagermanBot was only acting in line with a
well-established and agreed-upon understanding that the community had reached regarding
the importance of signatures in discussion spaces. For them, the burden was on the critics
to reach a consensus to amend the Signatures guideline if they wanted to stop the bot from
operating."
"placing strong moral emphasis on the role of signatures
and timestamps in maintaining discursive order and furthering the ideals of openness and
verifiability."

Opposers:
"did not directly contest the
claims made regarding the importance of signatures, discussion pages, and communicative
conventions."
"opposing view of how users, and
especially bot operators, ought to act toward each other in Wikipedia, a view that drew heavily
on notions of mutual respect:"

"botophobia"

end of the discussion: the HagermanBot should allow an opt-out mechanism

"Declarations of either side’s entitlements, largely articulated in the language of positive rights,
were displaced by the notion of responsibility, good behavior, and mutual respect."

"However, a
much stronger ally proved to be the opt-out list through which angry editors could be made to
lose interest in the debate altogether."
"The strength of the opt-out list was its flexibility in rebutting the objections from two kinds of
arguments: first, the largely under-articulated claims that the bot was annoying or trouble-
some to them; and second, the ideological or rights-based arguments that the bot was acting
against fundamental principles of the project’s normative structure."

an extention of the opt-out mechanism to all bots:
"However, seeing a need for extending this functionality to all possible bots, he [Rich Farmbrough]
created a template called {{nobots}}, which was to perform the same function as Hagerman-
Bot’s exclusion tag, except apply to all compliant bots."
"with no actual technical ability to restrict non-compliant bots from editing."

but the BAG can require a bot to comply with {{nobots}} in order to allow its operation

the compliance then found place in standard bot building toolkits

"The case of HagermanBot shows us how a weak but pre-existing social norm was controver-
sially reified into a technological actor."

"In all, bots defy simple single-sided categorizations: they are both editors and software, social
and technical, discursive and material, as well as assembled and autonomous."

============================================
\cite{HalTar2015}

"Today, we’re announcing the release of a new artificial intelligence service designed **to improve the way editors maintain the quality** of Wikipedia" (emphsis mine)
" This service empowers Wikipedia editors by helping them discover damaging edits and can be used to immediately “score” the quality of any Wikipedia article."

"these specs actually work to highlight potentially damaging edits for editors. This allows editors to triage them from the torrent of new edits and review them with increased scrutiny. " (probably triage the edits, not the specs)

"By combining open data and open source machine learning algorithms, our goal is to make quality control in Wikipedia more transparent, auditable, and easy to experiment with."

//so, purpose of ORES is quality control

"Our hope is that ORES will enable critical advancements in how we do quality control—changes that will both make quality control work more efficient and make Wikipedia a more welcoming place for new editors."

"ORES brings automated edit and article quality classification to everyone via a set of open Application Programming Interfaces (APIs). The system works by training models against edit- and article-quality assessments made by Wikipedians and generating automated scores for every single edit and article."

"English Wikipedians have long had automated tools (like Huggle and STiki ) and bots (like ClueBot NG) based on damage-detection AI to reduce their quality control workload.  While these automated tools have been amazingly effective at maintaining the quality of Wikipedia, they have also (inadvertently) exacerbated the difficulties that newcomers experience when learning about how to contribute to Wikipedia. "
"These tools encourage the rejection of all new editors’ changes as though they were made in bad faith," //NB!!!
"Despite evidence on their negative impact on newcomers, Huggle, STiki and ClueBot NG haven’t changed substantially since they were first introduced and no new tools have been introduced. " //what about the edit filters? when were Huggle,STiki and ClueBotNG introduced?

"decoupling the damage prediction from the quality control process employed by Wikipedians, we hope to pave the way for experimentation with new tools and processes that are both efficient and welcoming to new editors. "

caution: biases in AI
" An algorithm that flags edits as subjectively “good” or “bad”, with little room for scrutiny or correction, changes the way those contributions and the people who made them are perceived."

"Examples of ORES usage. WikiProject X’s uses the article quality model (wp10) to help WikiProject maintainers prioritize work (left). Ra·un uses an edit quality model (damaging) to call attention to edits that might be vandalism (right)." //interesting for the memo

"Popular vandal fighting tools, like the aforementioned Huggle, have already adopted our revision scoring service."

further ORES applications:
"  But revision quality scores can be used to do more than just fight vandalism. For example, Snuggle uses edit quality scores to direct good-faith newcomers to appropriate mentoring spaces,[4] and dashboards designed by the Wiki Education Foundation use automatic scoring of edits to surface the most valuable contributions made by students enrolled in the education program"

==========================================================
\cite{Kitchin2017}

importance of studying algorithms
viewpoints/perspectives/scientific traditions from which algorithms can be studied
challenges researchers face when trying to study algorithms
strategies for studying algorithms

"largely black boxed and beyond query or question"

common def of algorithms:
"set of defined steps to produce particular outputs"
"What constitutes an algorithm has changed over time"

different lenses to study them:
"technically, computationally, mathematically, politically, culturally, economically, contex-
tually, materially, philosophically, ethically and so on"

"formulation of an algorithm is, in theory at least, independent of programming languages"

translation challenges of coding
"translating a task or problem into a structured formula with an appropriate rule set (pseudo-code)."
"translating this pseudo-code into source code that when compiled will perform the task"

"The consequences of mistranslating
the problem and/or solution are erroneous outcomes and random uncertainties (Drucker,2013)."

"The processes of translation are often portrayed as technical, benign and commonsensical."

"As Montfort et al. (2012, p. 3) note, ‘[c]ode is not purely abstract and mathemat-
ical; it has significant social, political, and aesthetic dimensions,’"

"Nor can they escape factors such as available
resources and the choice and quality of training data; requirements relating to standards,
protocols and the law; and choices and conditionalities relating to hardware, platforms,
bandwidth and languages"

"algorithms are created for purposes that are often far from neutral"

algorithms change!
"creating an algorithm
unfolds in context through processes such as trial and error, play, collaboration, discussion
and negotiation. They are ontogenetic in nature (always in a state of becoming)"

"always somewhat uncertain, provisional and messy fragile accomplishments"

algorithms are not "stand-alone little boxes", but a socio-technical assemblage:
"complemented by many others, such
as researching the concept, selecting and cleaning data, tuning parameters, selling the idea
and product, building coding teams, raising finance and so on"

"reifying traditional pathologies, rather than reforming them"

not linear/predictable, bc
- part of a wider network
- have side effects
- subverting of computations made public

challenges:
- access/black boxed
  "Coding often happens in private settings, such as within companies"
  "since it is often a company’s algorithms that provide it with a competitive
advantage and they are reluctant to expose their intellectual property even with non-dis-
closure agreements in place."

- heterogeneous and embedded
  "rarely straightforward to deconstruct"
  "algorithms are usually woven together with hundreds of other algorithms"
  "it is unlikely that any one programmer has a complete understanding of a system, especially large, complex ones"

- ontogenetic, performative and contigent (always changing)
  "rarely fixed in form"
  "algorithms and their instantiation in
code are often being refined, reworked, extended and patched, iterating through various
versions"
  "no guarantee that the version a user interacts with at one moment in time is the same
as five seconds later"
  randomness might be built in
  "outcomes are sometimes not easily anticipated"

Approaches to studying algorithms
- Examining pseudo-code/source code
  "carefully deconstruct the pseudo-code and/or source code, teasing apart the
rule set to determine how the algorithm works to translate input to produce an outcome"
  "carefully siftign through documentation, code and programmer comments"
  "map out a genealogy of how an algorithm mutates and
evolves over time as it is tweaked and rewritten across different versions of code."
  "examine how the same task is translated into various software languages and how it
runs across different platforms."

  Limitations:
  not straightforward
  "Even those that have produced it can find it very difficult to unpack its algorithms and routines"
  "it requires that
the researcher is both an expert in the domain to which the algorithm refers and possesses
sufficient skill and knowledge as a programmer that they can make sense of a ‘Big Ball of
Mud’"
  "these approaches largely decontextualise the algorithm from its wider socio-technical assem-
blage and its use."

- Reflexively producing code
  "auto-ethnographies of translating tasks into pseudo-code"
  "researcher reflects on and critically interrogates their own experi-
ences of translating and formulating an algorithm."

  Limitations:
  "difficulties of detaching oneself and gaining critical distance"
  "excludes any non-representational, unconscious acts from analysis."
  "one generally wants to study algorithms and code that have real concrete effects on peoples’ everyday lives,"

- Reverse engineering
  "While software producers might desire their products to remain opaque, each pro-
gramme inherently has two openings that enable lines of enquiry: input and output"
  "carefully selected dummy data and seeing what is outputted under different scenarios"
  "follow debates on online forums by users about how they perceive an algorithm works"

  Limitations:
  "generally cannot do so with any specificity"
  "fuzzy glimpses"
  employ bots to test more systematically, many (proprietary) systems "seek to identify and block bot users."

- Interviewing designers or conducting an ethnography of a coding team
  "uncovering the story behind the production
of an algorithm and to interrogate its purpose and assumptions."
  "respondents are questioned as to how they framed objectives, created
pseudo-code and translated this into code,"
  "researcher seeks to spend time within a coding team,"

  Limitations
  "neither case are the specificities of algorithms and their
work unpacked and detailed."

- Unpacking the full socio-technical assemblage of algorithms
  "form part of a technological stack that includes infrastructure/hardware, code platforms, data and
interfaces, and are framed and conditions by forms of knowledge, legalities, governmen-
talities, institutions, marketplaces, finance and so on."
  "Interviews and ethnographies of coding projects, and the wider institutional apparatus
surrounding them (e.g., management and institutional collaboration)"

  Limitations:
  a lot of work!
  "manageable as a large case study,
especially if undertaken by a research team rather than a single individual."

- Examining how algorithms do work in the world
  "how they are deployed within different domains to perform a multitude of tasks."
  "what an algorithm is designed to do in theory and what it actually does in practice do not always correspond"
  "algorithms perform in context – in collaboration with data, technologies, people, etc. under varying conditions"
  "producing localised and situated outcomes."

===========================================================
\cite{GeiHal2013}

studies (EN) Wikipedia's quality control processes
in particular for 4 periods in 2011 when ClueBot NG (leading bot in vandalism fighting) was down
propose a typology of vandal fighting mechanisms:
* fully automated bots
* automation aided humans ("cyborgs") (e.g. human editors reverting vandalism via Huggle or STiki)
* manually editing humans (using the revert button or actually editing the article in a browser and clicking "save")
* batch scripts run for a particular occasion (e.g. revert all edits of malfunctioning bot or of a malicious editor)

time-to-revert is their primary metric
finds that median times to revert nearly doubled for the periods ClueBot NG was down
(also that Wikipedia editing activity is periodic, with uneven distribution of activity throughout a week, there are daily and weekly cycles)
also finds that more or less same amount of malicious edits were *eventually* reverted when the bot was down, it just took longer
(warns however, that they didn't study these situations further, e.g. by interviewing vandal fighters or similar, so it's unclear whether editors were putting in an extraordinary effort in order to maintain Wikipedia quality in an emergency situation and for how long this is possible)

ClueBot NG:
"to scan every edit made to Wikipedia in real time"
"Built on Bayesian neural networks and trained with data
about what kind of edits Wikipedians regularly revert as
vandalism"

"refining an edit is not considered a revert, and Wikipedians
are discouraged from excessively reverting edits made in
good faith. As such, reverts are the predominant
mechanism used to remove undesirable material, notably
vandalism and spam"

"Huggle, the most widely-used, fully assisted, counter-
vandalism tool, were made within 1 minute of the
offending edit. It is interesting that reverts with STiki, a
newer and more sophisticated queue-based vandal fighting
tool, are more often made to somewhat older edits, with a
time-to-revert distribution that is closer to unassisted edits.
This suggests that Huggle and STiki are targeting different
kinds of edits"

"bots like AWB, DumbBOT, and EmausBot are
less like the fully-automated counter-vandalism bots and
closer to batch scripts that routinely perform cleanup,
administrative, and categorization tasks."

===========================================================
\cite{HalRied2012}

"The first tools to redefine the
way Wikipedia dealt with van-
dalism were AntiVandalBot and
VandalProof."

"AntiVandalBot used a simple set
of rules and heuristics to monitor
changes made to articles, identify the
most obvious cases of vandalism, and
automatically revert them"

1st vandalism fighting bot:
"this bot made it possible, for the first
time, for the Wikipedia community
to protect the encyclopedia from
damage without wasting the time
and energy of good-faith editors"

"it
wasn’t very intelligent and could only
correct the most egregious instances
of vandalism."

"VandalProof, an early cyborg
technology, was a graphical user
interface written in Visual Basic that
let trusted editors monitor article
edits as fast as they happened in
Wikipedia and revert unwanted
contributions in one click."

"Several years and many iterations later [...] these tools have had an
increasing role in maintaining
article quality on Wikipedia."

"ClueBot _ NG has replaced
AntiVandalBot’s simple rules"

"Huggle has replaced VandalProof with
a slick user interface, configurablity,
and an intelligent system for sorting
edits by vandalistic likelihood"

"Huggle, one of the most popular
antivanda lism editing tools on
Wikipedia, is written in C#.NET
and any user can download and
install it. Huggle lets editors roll back
changes with a single mouse click,
but because the tool is so powerful,
rollback permission is restricted to
administrators and a few thousand
other Wikipedia users."
"Huggle makes it easy to review
a series of recent revisions by
filtering them according to the
user’s preferences."

huggle also sends out warnings to the offending editor on revert

"Some Wikipedians feel that such
motivational measures have gone
too far in making Wikipedia like a
game rather than a serious project.
One humorous entry even argues that
Wikipedia has become a MMORPG—
a massively multiplayer online role-
playing game—with “monsters”
(vandals) to slay, “experience”
(edit or revert count) to earn, and
“overlords” (administrators) to submit
to (http://en.wikipedia.org/wiki/
Wikipedia:MMORPG)."

==========================================
\cite{WestKanLee2010}

"STiki is an anti-vandalism tool for Wikipedia. Unlike similar tools, STiki does not rely on natural language
processing (NLP) over the article or diff text to locate vandalism"

"STiki leverages spatio-temporal properties of revision metadata."
"The feasibility of utilizing such properties was demonstrated in our prior
work, which found they perform comparably to NLP-efforts while being more efficient, robust to evasion, and
language independent."

"It consists of, (1) a server-side
processing engine that examines revisions, scoring the likelihood each is vandalism, and, (2) a client-side GUI
that presents likely vandalism to end-users for definitive classiffcation (and if necessary, reversion on
Wikipedia"

==========================================
\cite{GeiRib2010}

revealing invisible infrastructures via trace ethnography
reconstruct the collaboration between bots, editors using semi-automated tools and administrators for banning a vandal

"often-unofficial technologies have fundamentally
transformed the nature of editing and administration in
Wikipedia"
"Of note is the fact that these tools are largely
unofficial and maintained by members of the Wikipedia
community."

"„vandal fighting‟ as an
epistemic process of distributed cognition,"

"From autonomous
software agents and semi-automated programs to user
interface enhancements and visualization tools[...]
Together, they make possible a
kind of epistemological enforcement that often requires little
to no specific knowledge about a given article."

"we claim that in same way that the navigator of
a ship can know trajectories only through the work of dozens
of crew members, so is the blocking of a vandal a cognitive
process made possible by a complex network of interactions
between humans, encyclopedia articles, software systems, and
databases."

Partial explanation why literature paid little attention to (semi-)automated tools up to this date:
- old data according to which bots accounted for a very little amount of edits (2-4%)
  ("that this number has grown
dramatically: at present, bots make 16.33% of all edits.")
- "largely involved in single-use tasks like importing public domain material" (so not the case anymore, check e.g. MusikBot)
- "characterized in the literature as mere force-multipliers,
increasing the speed with which editors perform their work
while generally leaving untouched the nature of the tasks
themselves"

BotDef
"Bots – short for „robots‟ – are fully-automated software
agents that perform algorithmically-defined tasks involved
with editing, maintenance, and administration in Wikipedia."

"At present, some of the most
active bots are those that review every edit made in real time,
using sophisticated heuristics to revert blatant incidents of
spam and vandalism."

Check Figure 1: Edits to AIV by tool (in the meantime 10 years old. is there newer data on the topic??)

huggle description
"edits are contextually
presented in queues as they are made, and the user can
perform a variety of actions (including revert and warn) with
a single click. The software‟s built-in queuing mechanism,
which by default ranks edits according to a set of vandalism-
identification algorithms,"

"Users of Huggle‟s automatic
ranking mechanisms do not have to decide for themselves
which edit they will view next"

huggle's ranking heuristics:
"in the default „filtered‟ queue, edits that contain a significant removal of content are placed
higher; those that completely replace a page with blank text
are even marked in the queue with a red „X‟."
"anonymous users are viewed as more suspicious than
registered users, and edits by bots and Huggle users are not
even viewed at all."
"Users whose edits have been previously
reverted by a number of assisted users are viewed as even
more suspicious, and those who have been left warnings on
their user talk page (a process explained below) are
systematically sent to the top of the queue."

"This edit was placed into the queues of many
Huggle users, as the software prioritizes mass removal of
content by anonymous users who have vandalism warnings
left for them. In fact, a green “1” appeared next to the
article‟s name in the edit queue, indicating that a first-level
warning had been issued."

"In reporting the anonymous user to
AIV, the Huggle program collected three edits which had been
marked as vandalism in the previously-issued warnings."

"The Huggle software took note of the
fact that a report existed for this user at AIV, and asked the
administrator if he wished to issue a temporary block."

"Yet with four warnings and an active report at AIV, there was
nothing else Huggle could do in the name of this non-
administrator except append this incident of vandalism to his
original report, further attempting to enroll a willing
administrator into the ad-hoc vandal fighting network."

"“HBC AIV helperbot7” – automatically
removed the third vandal fighter‟s now-obsolete report."

Standard procedure for blocking:
"Generally, administrators will not temporarily
block users from editing if they have not received four
warnings."

"The work performed by many distinct vandal
fighters can be collated and then compressed into a single
number, visible to a wide array of human and non-human
actors."

Twinkle description:
"user interface extension that runs inside
of a standard web browser. Twinkle adds contextual links to
pages in Wikipedia allowing editors to perform complex tasks
with the click of a button – such as rolling back multiple edits
by a single user, reporting a problematic user to
administrators, nominating an article for deletion, and
temporarily blocking a user (for administrators only)."

Lupin's anti-vandal tool
"provides a real-
time in-browser feed of edits made matching certain
algorithms"

"user‟s talk page, which was more of database for other
vandal fighters than a space for dialogue with the anonymous
editor."

"While each editor made local
judgments as to the veracity or appropriateness of specific
contextualized edits, they collectively came to identify users
who were problematic and thus deserving of a temporary ban."

!! tools not only speed up the process but:
"These tools greatly lower certain barriers to participation and render editing
activity into work that can be performed by „average
volunteers‟ who may have little to no knowledge of the
content of the article at hand"

"Such a reviewing process is in
stark contrast to the more traditional forms of professional
and academic knowledge production"

"The domain expertise of vandal fighters is in the use of the
assisted editing tools themselves, and the kinds of
commonsensical judgment those tools enable."

Importance of diffs
"the edits in question
were rendered visibly suspicious because they were displayed
in such a manner."
"removal of entire
sections is a common form of vandalism that is difficult to
detect by merely reading the article."

"The Huggle program‟s queuing mechanism is another way in
which edits are further transformed, contextualized, and
abstracted"

"one does not need to have the
technical, literary, or academic skills or motivations to author
an article in order to patrol it."

"other users do not
have to trawl through the user‟s recent contributions: unassisted
vandal fighters can visit the user talk page to see previous
warnings, and assisted users simply have the software
automatically incorporate this information into its decision-
making process."

critical discussion
"Such acts of inclusion and exclusion may be necessary, but
they are inherently moral in quality, speaking to questions of
who is left out and what knowledge is erased."

"It is for
this reason that the argument that bots and assisted editing
tools are merely force multipliers is narrow and dangerous"

"In and outside of the Wikipedian community, tools
like Huggle are often compared with video games in both
serious critiques and humorous commentaries:"

"We should not fall into the trap of speaking of bots and
assisted editing tools as constraining the moral agency of
editors"

"these tools makes certain pathways of action easier for vandal
fighters and others harder"

"Similarly, users can
reconfigure their queues to not view anonymous edits as more
suspicious,"

"While these and many other workarounds are possible,
they require a greater effort and a certain technical savvy on
the part of their users."

"Ultimately, these tools take their users
through standardized scripts of action in which it always
possible to act otherwise, but such deviations demand
inventiveness and time."

======================================================================
\cite{Geiger2017}

situated in critical algorithmic studies, critical data studies,
discusses issues in fairness, accountability and transparency

(algorithmic) governance
gatekeeping

"the organizational culture of Wikipedia is deeply intertwined with various data-driven algorithmic
systems, which Wikipedians rely on to help manage and govern the ‘‘anyone can edit’’ encyclopedia at a massive
scale."
"These bots, scripts, tools, plugins, and dashboards make Wikipedia more efficient for those who know how
to work with them, but like all organizational culture, newcomers must learn them if they want to fully participate."

Beschreibt die Prozesse für 2 verschiedene, oft vorkommende Edit-Abläufe, mit den Bots und automatischen Tools, die diese unterstützen
* editing (your own) page on Wikipedia: Conflict of interest requests --> newcommers werden hier abgeschreckt
* Speedy Deletion

"But I realized that the more interesting question is why I had so internalized this socio-techni-
cal assemblage and the values it enacts." // People internalise the way a system works and stop questioning it!!

"They are deeply imbued with particular values, prin-
ciples, norms, and ideals, and learning them is not
just about technical competency, but also socialization
into a complex organizational culture"

Some descriptive statistics:
"In the English-language Wikipedia, 22 of the 25 most active editors (by
number of edits) are bot accounts, and July 2017, they made about 20% of all edits to encyclopedia articles."
--> vgl: https://quarry.wmflabs.org/query/20703

What does it take to be a Wikipedian:
"when that partici-
pation requires not only learning Wikipedia-specific
jargon, norms, style guides, and rules, but also learning
how to interact with all the bots and power tools"

"Wikipedia demonstrates how the issues in and around
algorithmic systems are as much social as they are tech-
nical, going far beyond the opacities that arise around
proprietary source code. My argument extends Burrell’s
(2016) discussion of three different forms of opacity in
machine learning: intentional secrecy (proprietary
source code), technical literacy (such as learning to
read code), and opacities inherent in machine learning
(such as issues of interpretability). To these forms, I add
another: the opacities in learning a particular institu-
tional or organizational culture that is supported by
algorithmic systems."
// source is open, but who can actually read it? and is willing to invest the time and energy in order to hold the system accountable?
// vgl auch Gedanke von Claudia: "Wikipedia is spannend, weil wir daran das erforschen können, was wir an Facebook nicht können. Und weil die ein Abbild der Gesellschaft im Kleinen ist."
// vgl auch Web Science def: observe micro behaviours in order to study macro phenomenons (governance, ..)

Def "algorithmic": "as involving encoded proced-
ures, which are typically—but not exclusively—compu-
tationally implemented."

"Like all algorithmic systems, the ones I studied in
Wikipedia were designed, developed, and deployed by
people." //all developers are human and all humans make mistakes^^

"As Gillespie (2014) argues: ‘‘A socio-
logical analysis must not conceive of algorithms as
abstract, technical achievements, but must unpack the
warm human and institutional choices that lie behind
these cold mechanisms.’’"

Seaver (2013: 9–10) Def Algorithmic System:
"It is not the algorithm, narrowly defined, that has
sociocultural effects, but algorithmic systems — intri-
cate, dynamic arrangements of people and code. . .
When we realize that we are not talking about algo-
rithms in the technical sense, but rather algorithmic
systems of which code strictu sensu is only a part,
their defining features reverse: instead of formality,
rigidity, and consistency, we find flux, revisability,
and negotiation."
"In this context, I ask: for whom are algorithmic systems
(and the organizations that rely on them) formal, rigid,
and consistent, and for whom are they in flux, revisable,
and negotiable?" //Vorwissen, das die Menschen mitbringen, ist wichtig!

2nd level digital divide:
"who had
the knowledge, skills, and sense of empowerment to use
the Internet in ways that further engaged, empowered,
and benefitted their lives." nach Hargittai 2002

Everything's open:
"We must look at more than the fact that partici-
pation in Wikipedia is open to the public; that the infra-
structure supporting it is open sourced; and that the
community’s policies, procedures, and norms are docu-
mented in thousands and thousands of pages of text."

BUT
"We must also look at what kind of skills, knowledge, and
investment is required to fully and successfully partici-
pate,"

speaks of deletion of substandard encyclopedic articles: Where and how are the standards defined? Who defines them?

"article about a
website fails the A7 criteria in the CSD process,
which demands that articles ‘‘credibly indicate the
importance or significance of the subject.’’ (A majority
of speedy deleted articles are tagged with templates
containing A7 rationales (Geiger and Ford, 2011).)"
// ich finde dieses Kriterium ist äußerst mit Vorsicht zu genießen, da die Tür weit aufgemacht wird für Sexismus, Rassismus und andere Arten von Diskriminierung von Inhalten, die der Mehrheit von white dudes nicht passen

"Yet I had a
second, subtler motivation, hoping that in properly
demonstrating correct usage of such a template within
the established workflow of this process, I would be
made legible as a Wikipedian who knew the CSD pro-
cess and should be given some more leeway—unlike
most of the people who were creating articles that
they were deleting." //making use of the brocode^^

"Such systems do not eliminate the need for human
labor, but instead transform the kind of work that
takes place,"

erwähnt auch Abschrecken von newcommers

"As
Seaver (2013) notes with his critiques of various ‘‘crit-
ical algorithms studies’’ literature, it is easy to slip into
a mode of analysis where social factors are contextua-
lized, while infrastructure remain static and determin-
ing. Such an approach ‘‘keeps algorithms themselves
untouched, objective stones tossed about in a roily
social stream’’ (10)."

"the algorithmic
systems themselves are constructed, negotiated, contex-
tualized, and differently interpreted and enacted." // aber wer kann beim Aushandeln mitmachen?

"Wikipedia’s computational infrastructure is
also designed and governed in a relatively open
manner by the project’s volunteer community of edi-
tors (Forte and Bruckman , 2008; Gilbert and Zachry,
2015; Kennedy, 2010), unlike most of the automated
systems that are increasingly prevalent in digitally
mediated environments." //jup. und selbst da blick man nicht durch

Requirements/Expectations for bot developers:
"bot developers are generally expected to be responsive
to reasonable requests and concerns from the
community."

"Wikipedians discuss and debate
about what kinds of bots should exist in the project,"

"one of the
paradoxes of openness is that it can take substantial
time, energy, investment, and resources to fully take
advantage of all the materials released"

Veterans vs newcomers:
"they make it far easier for veteran Wikipedians to
engage in the kind of specific, complex, multifacted
work involved in the governance of Wikipedia. This
can make it far more difficult for newcomers to partici-
pate—not necessarily because bots, algorithms, or
assisted tools are inherently difficult to deal with, but
rather because bots support more complex kinds of gov-
ernance practices in Wikipedia, and complex govern-
ance practices are difficult for newcomers."

